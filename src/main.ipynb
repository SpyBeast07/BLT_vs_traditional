{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853f066c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6894c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10000, 2)\n",
      "Test shape: (2000, 2)\n",
      "\n",
      "Train head:\n",
      "                                               input  \\\n",
      "0               reconciliation trolls realized scene   \n",
      "1                        scratched kemp blah devices   \n",
      "2  delusional engineered perfect prey englishman ...   \n",
      "3  boomers nfl reacts parallels everything 6 redu...   \n",
      "4  patience put christmas superhero luc rake fulf...   \n",
      "\n",
      "                                              target  \n",
      "0               enecs dezilaer sllort noitailicnocer  \n",
      "1                        secived halb pmek dehctarcs  \n",
      "2  hctarcs detsub namhsilgne yerp tcefrep dereeni...  \n",
      "3  stcudnoc ysereh redlof secuder 6 gnihtyreve sl...  \n",
      "4  ylesned ylno elbats latnenitnoc dellifluf ekar...  \n",
      "\n",
      "Test head:\n",
      "                                               input  \\\n",
      "0  intimidated campaigns emerging marines spin be...   \n",
      "1            salary lebanese wifi fury fab sta polly   \n",
      "2  financing ahmed sexual cinematic puff malibu p...   \n",
      "3  n00 nickel disparity funded tutorials constrai...   \n",
      "4  unveiled alliance cleric skinned illness permi...   \n",
      "\n",
      "                                              target  \n",
      "0  gnisnaelc leb nips seniram gnigreme sngiapmac ...  \n",
      "1            yllop ats baf yruf ifiw esenabel yralas  \n",
      "2  hcaep ubilam ffup citamenic lauxes demha gnicn...  \n",
      "3  tseilrae tidercsid yllatigid ssaprus ycacovda ...  \n",
      "4  denoitats deyortsed noissimrep ssenlli denniks...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"./../data/train.csv\"\n",
    "test_path = \"./../data/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\nTrain head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest head:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51648900",
   "metadata": {},
   "source": [
    "# BLT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a75530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using MPS (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ MPS not available, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996c3a4",
   "metadata": {},
   "source": [
    "## Patcher (entropy-based segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb0d88",
   "metadata": {},
   "source": [
    "**Shannon Entropy Function**\n",
    "\n",
    "Helper to compute entropy of a sequence of characters.\n",
    "\n",
    "H = - \\sum p(x) \\cdot \\log_2(p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82277daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def shannon_entropy(text: str) -> float:\n",
    "    \"\"\"Compute Shannon entropy of a string.\"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    counts = Counter(text)\n",
    "    probs = [count / len(text) for count in counts.values()]\n",
    "    return -sum(p * math.log2(p) for p in probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0b387",
   "metadata": {},
   "source": [
    "**Patcher Function**\n",
    "\n",
    "- Use sliding window of size W=10.\n",
    "- Keep adding characters to current patch until either:\n",
    "    - Entropy > threshold(2.0)\n",
    "    - Patch length > 15\n",
    "- Then start a new patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38e3a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(text: str, window_size=12, entropy_threshold=2.5, max_patch_len=20):\n",
    "    patches = []\n",
    "    current_patch = \"\"\n",
    "\n",
    "    for ch in text:\n",
    "        current_patch += ch\n",
    "\n",
    "        # Compute entropy only when window_size reached\n",
    "        entropy = (\n",
    "            shannon_entropy(current_patch[-window_size:])\n",
    "            if len(current_patch) >= window_size else 0\n",
    "        )\n",
    "\n",
    "        # Split condition: high entropy OR too long\n",
    "        if entropy > entropy_threshold or len(current_patch) >= max_patch_len:\n",
    "            if current_patch.strip():\n",
    "                patches.append(current_patch.strip())\n",
    "            current_patch = \"\"\n",
    "\n",
    "    # Add leftover patch\n",
    "    if current_patch.strip():\n",
    "        patches.append(current_patch.strip())\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14303cb",
   "metadata": {},
   "source": [
    "**Test Patcher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "957e4446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: reconciliation trolls realized scene\n",
      "Patches: ['reconciliati', 'on trolls re', 'alized scene']\n",
      "\n",
      "Text: LMA is fun!\n",
      "Patches: ['LMA is fun!']\n",
      "\n",
      "Text: aaaaabbbbbcccccddddd\n",
      "Patches: ['aaaaabbbbbcccccddddd']\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"reconciliation trolls realized scene\", # High entropy, more splits\n",
    "    \"LMA is fun!\", # Based on threshold, may not split\n",
    "    \"aaaaabbbbbcccccddddd\"  # low entropy predictable\n",
    "]\n",
    "\n",
    "for txt in sample_texts:\n",
    "    patches = patchify(txt)\n",
    "    print(f\"\\nText: {txt}\")\n",
    "    print(\"Patches:\", patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6433b9b",
   "metadata": {},
   "source": [
    "## Hash N-Gram Embeddings\n",
    "\n",
    "1. Extract all n-grams (n=1,2,3) from each patch.\n",
    "2. Map each n-gram into a bucket in [0, 4095].\n",
    "3. Use an embedding lookup table (nn.Embedding) to get a 64-d vector.\n",
    "4. Sum all vectors → final patch embedding (shape = [64])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7888f",
   "metadata": {},
   "source": [
    "**Hash Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "934382cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash_ngram(ngram: str, num_buckets=4096) -> int:\n",
    "    \"\"\"Hash an n-gram string into a bucket [0, num_buckets-1].\"\"\"\n",
    "    return int(hashlib.md5(ngram.encode(\"utf-8\")).hexdigest(), 16) % num_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1af6fd",
   "metadata": {},
   "source": [
    "**N-Gram Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d4f8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(text: str, n: int):\n",
    "    return [text[i:i+n] for i in range(len(text)-n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bc8a1",
   "metadata": {},
   "source": [
    "**Patch Embedding Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eaee92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchEmbedder(nn.Module):\n",
    "    def __init__(self, num_buckets=4096, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            \"1\": nn.Embedding(num_buckets, embed_dim),\n",
    "            \"2\": nn.Embedding(num_buckets, embed_dim),\n",
    "            \"3\": nn.Embedding(num_buckets, embed_dim),\n",
    "        })\n",
    "        # Xavier init\n",
    "        for emb in self.embeddings.values():\n",
    "            nn.init.xavier_uniform_(emb.weight)\n",
    "\n",
    "        self.num_buckets = num_buckets\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, patch: str):\n",
    "        \"\"\"Convert one patch string into a [embed_dim] vector.\"\"\"\n",
    "        vectors = []\n",
    "        # get device from embedding params\n",
    "        device = next(self.embeddings[\"1\"].parameters()).device  \n",
    "\n",
    "        for n in [1, 2, 3]:\n",
    "            ngrams = extract_ngrams(patch, n)\n",
    "            for ng in ngrams:\n",
    "                bucket = hash_ngram(ng, self.num_buckets)\n",
    "                idx = torch.tensor(bucket, dtype=torch.long, device=device)\n",
    "                vectors.append(self.embeddings[str(n)](idx))\n",
    "\n",
    "        if len(vectors) == 0:\n",
    "            return torch.zeros(self.embed_dim, device=device)\n",
    "\n",
    "        return torch.stack(vectors, dim=0).sum(dim=0)  # sum across n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350e4c9",
   "metadata": {},
   "source": [
    "**Test It on Sample Patches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61d18f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Patch: reconcilia | Embedding shape: torch.Size([64])\n",
      "Patch: tion troll | Embedding shape: torch.Size([64])\n",
      "Patch: s realized | Embedding shape: torch.Size([64])\n",
      "Patch:  scene | Embedding shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "embedder = PatchEmbedder().to(device)\n",
    "\n",
    "sample_patches = [\"reconcilia\", \"tion troll\", \"s realized\", \" scene\"]\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "for patch in sample_patches:\n",
    "    vec = embedder(patch)\n",
    "    print(f\"Patch: {patch} | Embedding shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a104ee9f",
   "metadata": {},
   "source": [
    "## BLT Dataset Class\n",
    "\n",
    "This dataset will:\n",
    "1. Read train.csv / test.csv.\n",
    "2. For each row:\n",
    "    - Take input string → apply patchify → embed patches into [seq_len, 64].\n",
    "    - Take target string → here we’ll keep it character-level for decoder supervision (simpler than patching the output).\n",
    "3. Return tensors for (src_seq, tgt_seq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6c261c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "PRINTABLE_ASCII = [chr(i) for i in range(32, 127)]\n",
    "VOCAB = ['<PAD>', '<SOS>', '<EOS>'] + PRINTABLE_ASCII # PAD=0, SOS=1, EOS=2\n",
    "\n",
    "# Mapping from character to index\n",
    "CHAR_TO_IDX = {ch: i for i, ch in enumerate(VOCAB)}\n",
    "PAD_IDX = CHAR_TO_IDX['<PAD>']\n",
    "SOS_IDX = CHAR_TO_IDX['<SOS>']\n",
    "EOS_IDX = CHAR_TO_IDX['<EOS>']\n",
    "\n",
    "\n",
    "class BLTDataset(Dataset):\n",
    "    def __init__(self, csv_path, window_size=12, entropy_threshold=2.5, max_patch_len=20):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.window_size = window_size\n",
    "        self.entropy_threshold = entropy_threshold\n",
    "        self.max_patch_len = max_patch_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        inp, tgt = row[\"input\"], row[\"target\"]\n",
    "\n",
    "        patches = patchify(inp, \n",
    "                            window_size=self.window_size,\n",
    "                            entropy_threshold=self.entropy_threshold,\n",
    "                            max_patch_len=self.max_patch_len)\n",
    "\n",
    "        # The vocabulary mapping\n",
    "        tgt_ids = [CHAR_TO_IDX.get(c, PAD_IDX) for c in tgt] \n",
    "        tgt_tensor = torch.tensor([SOS_IDX] + tgt_ids + [EOS_IDX], dtype=torch.long)\n",
    "\n",
    "        return patches, tgt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daa5889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Source Data (Input):\n",
      "   - Type: <class 'list'>\n",
      "   - Number of patches: 3\n",
      "   - Patches content (first 5): ['reconciliati', 'on trolls re', 'alized scene']\n",
      "\n",
      "2. Target Data (Output):\n",
      "   - Type: <class 'torch.Tensor'>\n",
      "   - Shape: torch.Size([38])\n",
      "   - Dtype: torch.int64\n",
      "   - Content (first 15 IDs): [1, 72, 81, 72, 70, 86, 3, 71, 72, 93, 76, 79, 68, 72, 85]\n",
      "\n",
      "3. Target String Reconstruction:\n",
      "   - Reconstructed: <SOS>enecs dezilaer sllort noitailicnocer<EOS>\n",
      "   - Original:      <SOS>enecs dezilaer sllort noitailicnocer<EOS>\n"
     ]
    }
   ],
   "source": [
    "IDX_TO_CHAR = {i: ch for ch, i in CHAR_TO_IDX.items()}\n",
    "train_ds = BLTDataset(csv_path=\"./../data/train.csv\")\n",
    "src_patches, tgt_tensor = train_ds[0]\n",
    "\n",
    "print(\"\\n1. Source Data (Input):\")\n",
    "print(f\"   - Type: {type(src_patches)}\")\n",
    "print(f\"   - Number of patches: {len(src_patches)}\")\n",
    "print(f\"   - Patches content (first 5): {src_patches[:5]}\")\n",
    "\n",
    "print(\"\\n2. Target Data (Output):\")\n",
    "print(f\"   - Type: {type(tgt_tensor)}\")\n",
    "print(f\"   - Shape: {tgt_tensor.shape}\")\n",
    "print(f\"   - Dtype: {tgt_tensor.dtype}\")\n",
    "print(f\"   - Content (first 15 IDs): {tgt_tensor[:15].tolist()}\") # .tolist() for clean printing\n",
    "\n",
    "# 3. Check the reconstruction\n",
    "reconstructed_string = \"\".join([IDX_TO_CHAR.get(i.item(), '') for i in tgt_tensor])\n",
    "print(\"\\n3. Target String Reconstruction:\")\n",
    "print(f\"   - Reconstructed: {reconstructed_string}\")\n",
    "\n",
    "original_target = train_df.iloc[0]['target']\n",
    "print(f\"   - Original:      <SOS>{original_target}<EOS>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780e7a1",
   "metadata": {},
   "source": [
    "## Collate Function for BLT\n",
    "\n",
    "We’ll:\n",
    "1. Take a batch of (src_seq, tgt_seq).\n",
    "2. Pad src_seq to [batch, max_src_len, 64].\n",
    "3. Pad tgt_seq to [batch, max_tgt_len].\n",
    "4. Return padded tensors + lengths (useful for masking in the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89b5f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def blt_collate_fn(batch):\n",
    "    # batch is a list of (patches, tgt_tensor)\n",
    "    src_patches, tgt_seqs = zip(*batch)\n",
    "\n",
    "    # Pad target sequences (char IDs)\n",
    "    tgt_padded = pad_sequence(tgt_seqs, batch_first=True, padding_value=0) # Assuming 0 is PAD_IDX\n",
    "\n",
    "    # The source patches remain a list of lists of strings\n",
    "    # e.g., [ ['patch1', 'patch2'], ['p1', 'p2', 'p3'], ... ]\n",
    "    return list(src_patches), tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47d6674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sanity Check on DataLoader\n",
      "\n",
      "1. Source Data Batch (Input):\n",
      "   - Type: <class 'list'>\n",
      "   - Length (Batch Size): 8\n",
      "   - Content of first item in batch: ['harrington +', 'm foot live', 'r fossils me', 'lody excite', 'explicitly t', 'rough winger', 's phases par', 'alyzed melt']\n",
      "\n",
      "2. Target Data Batch (Output):\n",
      "   - Type: <class 'torch.Tensor'>\n",
      "   - Shape (Batch Size, Max Target Length): torch.Size([8, 120])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.9 * len(train_ds))\n",
    "val_size   = len(train_ds) - train_size\n",
    "train_subset, val_subset = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=blt_collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=blt_collate_fn\n",
    ")\n",
    "\n",
    "print(\"Running Sanity Check on DataLoader\")\n",
    "src_patches_batch, tgt_padded_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"\\n1. Source Data Batch (Input):\")\n",
    "print(f\"   - Type: {type(src_patches_batch)}\")\n",
    "print(f\"   - Length (Batch Size): {len(src_patches_batch)}\")\n",
    "print(f\"   - Content of first item in batch: {src_patches_batch[0]}\")\n",
    "\n",
    "print(\"\\n2. Target Data Batch (Output):\")\n",
    "print(f\"   - Type: {type(tgt_padded_batch)}\")\n",
    "print(f\"   - Shape (Batch Size, Max Target Length): {tgt_padded_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b0951",
   "metadata": {},
   "source": [
    "## BLT Model Architecture\n",
    "\n",
    "Core Idea:\n",
    "1. Encoder: Take patch embeddings [B, L, 64], map into hidden dimension with a transformer encoder.\n",
    "2. Decoder: Generate characters (IDs) step by step using a transformer decoder.\n",
    "3. Output layer: Linear projection → vocab size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40936686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Note: In our implementation, we use batch_first=True, so the shape is [B, L, D].\n",
    "        # The stored pe is [max_len, 1, D]. We need to adjust it for batch.\n",
    "        x = x + self.pe[:x.size(1)].transpose(0, 1) # Transpose to [1, L, D] to broadcast\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f28faa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Assume PatchEmbedder, PositionalEncoding, and helper functions are defined above\n",
    "\n",
    "class BLTModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=64, nhead=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.patch_embedder = PatchEmbedder(num_buckets=4096, embed_dim=d_model)\n",
    "        self.global_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        self.tgt_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=dropout)\n",
    "\n",
    "        # --- ARCHITECTURE (1-1-2 STRUCTURE) ---\n",
    "        # 1. ENCODER (1 Block)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, \n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        # FIX: Added 'enable_nested_tensor=False' for MPS compatibility\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=1, enable_nested_tensor=False)\n",
    "\n",
    "        # 2. GLOBAL TRANSFORMER (2 Blocks)\n",
    "        global_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        # FIX: Added 'enable_nested_tensor=False' for MPS compatibility\n",
    "        self.global_transformer = nn.TransformerEncoder(global_layer, num_layers=2, enable_nested_tensor=False)\n",
    "\n",
    "        # 3. DECODER (1 Block)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=1)\n",
    "\n",
    "        # --- FINAL OUTPUT LAYER ---\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src_patches_batch, tgt_inp, tgt_pad_mask=None):\n",
    "        # src_patches_batch: A list (size B) of lists of patch strings\n",
    "        # tgt_inp: [B, Lt] (character IDs for teacher forcing)\n",
    "        \n",
    "        device = self.global_token.device\n",
    "\n",
    "        # --- 1. Get Patch Embeddings and Pad ---\n",
    "        batch_embeddings = []\n",
    "        for patch_list in src_patches_batch:\n",
    "            if not patch_list:\n",
    "                sample_emb = torch.zeros(1, self.d_model, device=device)\n",
    "            else:\n",
    "                sample_emb = torch.stack([self.patch_embedder(p) for p in patch_list])\n",
    "            batch_embeddings.append(sample_emb)\n",
    "        \n",
    "        src_emb = pad_sequence(batch_embeddings, batch_first=True, padding_value=0.0)\n",
    "        B, Ls, _ = src_emb.shape\n",
    "\n",
    "        # --- 2. Prepend Global Token ---\n",
    "        global_token_batch = self.global_token.expand(B, -1, -1)\n",
    "        encoder_input = torch.cat([global_token_batch, src_emb], dim=1)\n",
    "        encoder_input = self.pos_encoder(encoder_input)\n",
    "\n",
    "        # --- 3. Pass through 1-Block Encoder ---\n",
    "        src_key_padding_mask = (torch.cat([\n",
    "            torch.zeros(B, 1, device=device), # Mask for global token is False\n",
    "            src_emb.sum(dim=-1) == 0 # Mask for padded patches is True\n",
    "        ], dim=1)).bool()\n",
    "        \n",
    "        encoder_output = self.encoder(encoder_input, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # --- 4. Isolate Global Token and Pass through 2-Block Global Transformer ---\n",
    "        global_context = encoder_output[:, 0:1, :]\n",
    "        memory = self.global_transformer(global_context)\n",
    "\n",
    "        # --- 5. Pass through 1-Block Decoder ---\n",
    "        tgt_emb = self.pos_encoder(self.tgt_embed(tgt_inp))\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(tgt_inp.size(1)).to(device)\n",
    "        \n",
    "        decoder_output = self.decoder(\n",
    "            tgt=tgt_emb,\n",
    "            memory=memory,\n",
    "            tgt_mask=causal_mask,\n",
    "            tgt_key_padding_mask=tgt_pad_mask\n",
    "        )\n",
    "        \n",
    "        # --- 6. Final Projection ---\n",
    "        normalized_output = self.norm(decoder_output)\n",
    "        logits = self.output_proj(normalized_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e965f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Model Sanity Check ---\n",
      "Logits shape: torch.Size([8, 133, 98])\n",
      "Expected shape: (8, 133, 98)\n",
      "\n",
      "✅ Shapes are correct and ready for the training loop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assume your vocab (VOCAB, PAD_IDX), dataloaders, and model classes are defined above\n",
    "\n",
    "# --- Step 1: Correct the Hyperparameters ---\n",
    "# The vocabulary is printable ASCII (95 chars) + 3 special tokens, not 256.\n",
    "VOCAB_SIZE = len(VOCAB) # This should be 98\n",
    "D_MODEL = 64            # As per the assignment [cite: 22]\n",
    "N_HEAD = 4\n",
    "DROPOUT = 0.1\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# --- Step 2: Correct the Model Instantiation ---\n",
    "# Use the new model's argument names (vocab_size, d_model, etc.)\n",
    "model = BLTModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=N_HEAD,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# --- Step 3: Correct the Batch Handling and Model Call ---\n",
    "\n",
    "# Fetch a single batch from your train_loader\n",
    "# Unpack the 2 items returned by your collate_fn: a list of patches and a padded tensor\n",
    "src_patches_batch, tgt_padded_batch = next(iter(train_loader))\n",
    "tgt_padded_batch = tgt_padded_batch.to(device)\n",
    "\n",
    "# Prepare for Teacher Forcing\n",
    "tgt_inp = tgt_padded_batch[:, :-1]  # All but the last token\n",
    "tgt_out = tgt_padded_batch[:, 1:]   # All but the first token\n",
    "\n",
    "# Create the padding mask for the decoder input\n",
    "tgt_pad_mask = (tgt_inp == PAD_IDX)\n",
    "\n",
    "# Call the model with the correct arguments for the new forward pass\n",
    "# (a list of patches, the input tensor, and the padding mask)\n",
    "logits = model(src_patches_batch, tgt_inp, tgt_pad_mask)\n",
    "\n",
    "\n",
    "# --- Step 4: Check the Output Shape ---\n",
    "print(\"--- Final Model Sanity Check ---\")\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Expected shape: ({tgt_out.shape[0]}, {tgt_out.shape[1]}, {VOCAB_SIZE})\")\n",
    "\n",
    "assert logits.shape[0] == tgt_out.shape[0]\n",
    "assert logits.shape[1] == tgt_out.shape[1]\n",
    "assert logits.shape[2] == VOCAB_SIZE\n",
    "print(\"\\n✅ Shapes are correct and ready for the training loop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25767bd",
   "metadata": {},
   "source": [
    "## Training Loop + Checkpoints\n",
    "\n",
    "We’ll set up:\n",
    "1. Loss = CrossEntropyLoss(ignore_index=0) (ignores PAD tokens).\n",
    "2. Optimizer = Adam.\n",
    "3. Training loop with logging.\n",
    "4. Checkpoint saving (state_dict, optimizer, epoch, loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "361dc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# Training loop for BLT model\n",
    "# ----------------------------\n",
    "def train_blt(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    device,\n",
    "    save_every,\n",
    "    resume_path=None\n",
    "):\n",
    "    print(f\"Training on: {device}\")\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX) # Use your defined PAD_IDX\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", factor=0.5, patience=5)\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    # Resume\n",
    "    start_epoch = 1\n",
    "    if resume_path and os.path.exists(resume_path):\n",
    "        print(f\"🔄 Resuming from checkpoint: {resume_path}\")\n",
    "        checkpoint = torch.load(resume_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        if \"scheduler_state\" in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "        print(f\"✅ Resumed from epoch {checkpoint['epoch']} (loss {checkpoint['loss']:.4f})\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Training]\")\n",
    "\n",
    "        for src_patches, tgt_padded in progress_bar:\n",
    "            tgt_padded = tgt_padded.to(device)\n",
    "            tgt_inp = tgt_padded[:, :-1]\n",
    "            tgt_out = tgt_padded[:, 1:]\n",
    "            tgt_pad_mask = (tgt_inp == PAD_IDX)\n",
    "\n",
    "            logits = model(src_patches, tgt_inp, tgt_pad_mask)\n",
    "            loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * tgt_out.numel()\n",
    "            total_tokens += tgt_out.numel()\n",
    "\n",
    "        avg_loss = total_loss / total_tokens if total_tokens > 0 else 0\n",
    "        print(f\"\\n📘 Epoch {epoch}/{num_epochs} - Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        perplexity = math.exp(val_loss) if val_loss < 100 else float('inf')\n",
    "        print(f\"📗 Validation - Loss: {val_loss:.4f}, Perplexity: {perplexity:.2f}, Token Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if epoch % save_every == 0 or epoch == num_epochs:\n",
    "            ckpt_path = f\"checkpoints/blt_epoch{epoch}.pt\"\n",
    "            torch.save({ \"epoch\": epoch, \"model_state\": model.state_dict(), \"optimizer_state\": optimizer.state_dict(), \"scheduler_state\": scheduler.state_dict(), \"loss\": avg_loss }, ckpt_path)\n",
    "            print(f\"✅ Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "\n",
    "    for src_patches, tgt_padded in progress_bar:\n",
    "        tgt_padded = tgt_padded.to(device)\n",
    "        tgt_inp = tgt_padded[:, :-1]\n",
    "        tgt_out = tgt_padded[:, 1:]\n",
    "        tgt_pad_mask = (tgt_inp == PAD_IDX)\n",
    "        \n",
    "        logits = model(src_patches, tgt_inp, tgt_pad_mask)\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        \n",
    "        total_loss += loss.item() * (tgt_out != PAD_IDX).sum().item() # Count non-padded tokens for loss\n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = (tgt_out != PAD_IDX)\n",
    "        correct_tokens += ((preds == tgt_out) & mask).sum().item()\n",
    "        total_tokens += mask.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_tokens if total_tokens > 0 else 0\n",
    "    accuracy = 100.0 * correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b94386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f04a76f02d4adcbe81097d429cc1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 1/300 - Train Loss: 2.9616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed21c8bd43f74018a0a4d2d5067e8009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.6513, Perplexity: 14.17, Token Acc: 21.77%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1747840f18d74e159546b1a386e906e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 2/300 - Train Loss: 2.6379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed91969e14304ec998eb453f7450e5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.5659, Perplexity: 13.01, Token Acc: 23.33%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0c311dd4754d4b8d6b39a735b965d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 3/300 - Train Loss: 2.5791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0432429f3f54dbeacc56cccb99cafab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.5193, Perplexity: 12.42, Token Acc: 24.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3da82d7112645edb7ade174f3002d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 4/300 - Train Loss: 2.5480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2903e496ef834dfd8c115c7da204cd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.4904, Perplexity: 12.07, Token Acc: 25.07%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1419687c284d5c9119e92b89288eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 5/300 - Train Loss: 2.5237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc32530728f34edb8c3bd6963336d025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.4670, Perplexity: 11.79, Token Acc: 25.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8f9cfe24cd422bb545c605d027eab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 6/300 - Train Loss: 2.5072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ab347360f54a1faf83832e3c16b8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.4503, Perplexity: 11.59, Token Acc: 25.99%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch6.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a8bb9e05f64d79a45f6bad61a99415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 7/300 - Train Loss: 2.4921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100eff1997764798b119beb79aa8fa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.4355, Perplexity: 11.42, Token Acc: 26.56%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601e4cdf66154f9eac2ff8933bdf9bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 8/300 - Train Loss: 2.4790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6977635b4447528f4189c61a0237e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.4185, Perplexity: 11.23, Token Acc: 26.98%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca702de63ef8488fbfecb1165105274d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 9/300 - Train Loss: 2.4673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37baeaed757e44e895ec43d265d54a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.4044, Perplexity: 11.07, Token Acc: 27.37%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19d6eafea6a4a0682a38fd6ce75b754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 10/300 - Train Loss: 2.4569\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b668452952a74d0695e4a6be54236d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3925, Perplexity: 10.94, Token Acc: 27.67%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch10.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5395997a4aa6412e9409ff4c9004ad65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 11/300 - Train Loss: 2.4471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5b05d65bd74bfcb9542d611ed073f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3818, Perplexity: 10.82, Token Acc: 28.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318fcc29ecd94b60aa1fc3b4852de47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 12/300 - Train Loss: 2.4385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10e4a1a57a74139ab942c0a409319ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3719, Perplexity: 10.72, Token Acc: 28.35%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch12.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5770951091974b7c9d4e872282d748c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 13/300 - Train Loss: 2.4301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b086c07b5d465289c467ea7d9f7503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3610, Perplexity: 10.60, Token Acc: 28.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2822b7821f5a46168f11d477c8f1ae09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 14/300 - Train Loss: 2.4217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50132c2db0f143f0b58e386a67fb10e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3521, Perplexity: 10.51, Token Acc: 28.80%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch14.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b117e143fc42a19dea2167fcc60e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 15/300 - Train Loss: 2.4137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8d5ba62396456988a9d87e60cac9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3401, Perplexity: 10.38, Token Acc: 29.16%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ff470978804d19aa3ba75917ab4490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 16/300 - Train Loss: 2.4059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f913eedf7014fcba071ae8670d65ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3329, Perplexity: 10.31, Token Acc: 29.30%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch16.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6443a7e98a20429292be3c58152f53d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 17/300 - Train Loss: 2.3987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41919b790369428eb7df9e602443ceb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3241, Perplexity: 10.22, Token Acc: 29.66%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003d854485ca4f88bdb0f7f9bf18630b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 18/300 - Train Loss: 2.3924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c41b0a81bc146af9d5cf6f883874aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3175, Perplexity: 10.15, Token Acc: 29.81%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch18.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57b6ebec5454ed196a0d195f884b7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 19/300 - Train Loss: 2.3872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4ee30179b24c5ab7a6ac150ae06b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3073, Perplexity: 10.05, Token Acc: 30.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db48a529c76f4175a275c01977a122d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 20/300 - Train Loss: 2.3803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb7aa9a66604f00bf55ed62d69e8619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.3012, Perplexity: 9.99, Token Acc: 30.27%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch20.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50421809aaed48e7a27caa5d3f0c97b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 21/300 - Train Loss: 2.3749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc0a1f203e3470bb42253484775614c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2963, Perplexity: 9.94, Token Acc: 30.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e96be162c24c0eb6f7e747fd5e7991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 22/300 - Train Loss: 2.3698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1547be90a8a46e0afd0867c30877a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2889, Perplexity: 9.86, Token Acc: 30.48%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch22.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a369274afa4e41a628c2c1ba5df150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 23/300 - Train Loss: 2.3638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a33cb4182249558fdccf3ac2ef1ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2832, Perplexity: 9.81, Token Acc: 30.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8556ce6bcbe4b32b3d0b1ecd5598c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 24/300 - Train Loss: 2.3587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7e43da6a01407d9f70bcd519f9de23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2751, Perplexity: 9.73, Token Acc: 30.90%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch24.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c6641fb23549ab96527453c88008a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 25/300 - Train Loss: 2.3535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9041eedccd34e1aafe462e229b08e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2715, Perplexity: 9.69, Token Acc: 31.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcf6d2f534e498f9701adafb582e423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 26/300 - Train Loss: 2.3497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52d342fd3854120a080cb5ff4e8b73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2653, Perplexity: 9.63, Token Acc: 31.27%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch26.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85db64e1183c4d1a8efd76ab4a03bdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 27/300 - Train Loss: 2.3457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2f0a211f454f86afd1a4347c70f7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2609, Perplexity: 9.59, Token Acc: 31.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb0a1241e134dc98af03594077cf66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 28/300 - Train Loss: 2.3420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3e53f203f9448b95e7df68535c54bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2555, Perplexity: 9.54, Token Acc: 31.51%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch28.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f0a9e13fa645f98eb65fee1f536ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 29/300 - Train Loss: 2.3379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff86b125c1824a0a94209b767388f463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2511, Perplexity: 9.50, Token Acc: 31.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a06cd252dc047049cdf4a26d644dbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 30/300 - Train Loss: 2.3345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed87f69565b49a6a7c47aa60efc1800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2470, Perplexity: 9.46, Token Acc: 31.80%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch30.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e892b91af2324d619e895632f6a604c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 31/300 - Train Loss: 2.3300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4767a3595a465fbff6c1c19786f7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2431, Perplexity: 9.42, Token Acc: 31.87%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397fa58f71cd42caaf8f87f606896326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 32/300 - Train Loss: 2.3269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30648e2021ec4347bd9ed19fc4fe3a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2389, Perplexity: 9.38, Token Acc: 31.96%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch32.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a100b4ff86f64ce99aced11a0f84cf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 33/300 - Train Loss: 2.3228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a99041e45544a4b2b7b72ea7f288f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2354, Perplexity: 9.35, Token Acc: 32.19%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f18b21564a494196b53c742a47bfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 34/300 - Train Loss: 2.3200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008ac1d0f8ce45f3a3e0f57ea0c88de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2303, Perplexity: 9.30, Token Acc: 32.21%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch34.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f6add611cb46b3a07b482f9c05ac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 35/300 - Train Loss: 2.3156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa90d4cabed4fb3951439232a815d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2235, Perplexity: 9.24, Token Acc: 32.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b997aa4a1284758a6632a4758392ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 36/300 - Train Loss: 2.3117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fd1e01dd9b44e5a25ad57166053f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2188, Perplexity: 9.20, Token Acc: 32.62%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch36.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771e6c6f787744e1b10cd899276de150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 37/300 - Train Loss: 2.3089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519ca4ced2c046349755645beaf9dd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2160, Perplexity: 9.17, Token Acc: 32.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec725735831a4028bf4d83eec32dbd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 38/300 - Train Loss: 2.3056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d781ab84c9b740a19584f4834561f00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2136, Perplexity: 9.15, Token Acc: 32.79%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch38.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93578ef1f5d4852b1f8a2f6680cefc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 39/300 - Train Loss: 2.3026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2146e29e4844f5584061fc5c63091d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2091, Perplexity: 9.11, Token Acc: 32.89%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4894c31f532f4f84bae38a27b482931b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 40/300 - Train Loss: 2.2995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cf5d0f000641f5b6b8be50ac8e63a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2043, Perplexity: 9.06, Token Acc: 33.12%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch40.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f4b27d98454128b4d4218536bf3711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 41/300 - Train Loss: 2.2968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abc57b1451c4a9ebc749aa9824be1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.2012, Perplexity: 9.04, Token Acc: 33.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3791915cbc246608e5110778cb36a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 42/300 - Train Loss: 2.2931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbdde4246d2445cb101574e39bcd8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1987, Perplexity: 9.01, Token Acc: 33.20%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch42.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1193934da194b639dc1df797a95b3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 43/300 - Train Loss: 2.2889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04655fdc66514d06aaf7ea7b5e9af83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1929, Perplexity: 8.96, Token Acc: 33.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f542c9e670524e75aca6a41c01e0eb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 44/300 - Train Loss: 2.2879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f371facbb1466684cf6043adbc8054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1899, Perplexity: 8.93, Token Acc: 33.41%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch44.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588aab0f41bf445a81bee62a64a6fead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 45/300 - Train Loss: 2.2837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d795dca50ceb443fbc89bfc41d61f976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1857, Perplexity: 8.90, Token Acc: 33.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a35952b05e74aad8cc27ef3fa244b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 46/300 - Train Loss: 2.2807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cc620d31504ac18eb4e2e03ffdee89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1828, Perplexity: 8.87, Token Acc: 33.61%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch46.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf68548a07944529b725115a605bd469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 47/300 - Train Loss: 2.2778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12802ea99a2a414f9593e68b859877ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1778, Perplexity: 8.83, Token Acc: 33.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f314af6a4a49628da9ef2c0e752d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 48/300 - Train Loss: 2.2748\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73190e1cace4c26bcf38454a6ac5181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1746, Perplexity: 8.80, Token Acc: 33.71%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch48.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba15030b3e84bd3b395449e108e98c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 49/300 - Train Loss: 2.2729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766c248bc4ed4385841cbe667b1c18cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1707, Perplexity: 8.76, Token Acc: 34.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609adaf3eb7b405f9aedf52d08dc9abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 50/300 - Train Loss: 2.2708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d292ab9e43449594ac1a23a61db7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1683, Perplexity: 8.74, Token Acc: 33.97%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch50.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4b1db8af774827aeb4f7e04534f1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 51/300 - Train Loss: 2.2672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763e83c15d4c402f98b7d8ffb6e38437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1674, Perplexity: 8.74, Token Acc: 34.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f4132d472247a79e869bd1b9abece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 52/300 - Train Loss: 2.2656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4374daf5a2a4f03a02e24f8c15e69b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1633, Perplexity: 8.70, Token Acc: 34.06%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch52.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35e7cfcd43146f59459411888e75b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 53/300 - Train Loss: 2.2634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d573fda3ea4c279b7682983e8d1559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1605, Perplexity: 8.68, Token Acc: 34.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cb722cd6d74de7a9b6e9f5eff1ff9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 54/300 - Train Loss: 2.2608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26050b2ef4f74b07b749deb824afefd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1569, Perplexity: 8.64, Token Acc: 34.35%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch54.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80c2f6914f04964b56c66449f7310e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 55/300 - Train Loss: 2.2578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8054e7462986480cad1708f7b7cceae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1541, Perplexity: 8.62, Token Acc: 34.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e0b067d335437d96ed5ad8f379920d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 56/300 - Train Loss: 2.2558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce817d4b7a5f4b998ac477151059e7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1521, Perplexity: 8.60, Token Acc: 34.43%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch56.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5862dbf068849a5864ab4242f50946d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 57/300 - Train Loss: 2.2533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fae234bec24966b5b10e834e0bfe9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1492, Perplexity: 8.58, Token Acc: 34.53%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a575b0e8eb5346598b46b0d06d34f45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 58/300 - Train Loss: 2.2504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99fee6d743a49f7883f56067a82d848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1476, Perplexity: 8.56, Token Acc: 34.40%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch58.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82e32a10af54a8da9cd979aafea098d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 59/300 - Train Loss: 2.2494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f138e52326b24eddb4e7796c423b644c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1448, Perplexity: 8.54, Token Acc: 34.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c75836e1d914c709018b2870f09a526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 60/300 - Train Loss: 2.2475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9bc6a26c3940718a578a70ad3fbef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1417, Perplexity: 8.51, Token Acc: 34.68%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch60.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbff469c22747f1b431aec93c5d1834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 61/300 - Train Loss: 2.2446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8725fbf5709949c9a783125364ad5f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1382, Perplexity: 8.48, Token Acc: 34.72%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61da6f0d3c02452cae9560c952b55444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 62/300 - Train Loss: 2.2426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2521bbf0d54318bb05b32bb47666d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1354, Perplexity: 8.46, Token Acc: 34.80%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch62.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c039114d17437e808b98b2ec5a6136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 63/300 - Train Loss: 2.2398\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170cc29c5e984c4d8444a24e2d485997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1336, Perplexity: 8.45, Token Acc: 34.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb63496e63e3418586cfb7f5a0b2cf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 64/300 - Train Loss: 2.2383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befe1693097740598c6b586668178afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1305, Perplexity: 8.42, Token Acc: 34.99%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch64.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a71a59d9c0248adad5b0a9b1be169d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 65/300 - Train Loss: 2.2364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aade8090cacd4fd3ab87f85030e7f50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1287, Perplexity: 8.40, Token Acc: 35.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669ce1b4d9894f5595127b42d8675d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 66/300 - Train Loss: 2.2336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f31cc2c0fdb47c3ac443a3ae82f166d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1262, Perplexity: 8.38, Token Acc: 35.12%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch66.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5d6fbdef5f44ef85a6b2276ed6841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 67/300 - Train Loss: 2.2333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f40d6f9d044af291cc20f06dd4cb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1227, Perplexity: 8.35, Token Acc: 35.16%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd9c0a094d94371bf8762b4cba8e5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 68/300 - Train Loss: 2.2309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3933045e9c60499bb04e27b4f925f5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1220, Perplexity: 8.35, Token Acc: 35.22%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch68.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb8ff37a0b74b69ab99c0b96a71b216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 69/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 69/300 - Train Loss: 2.2286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb3784adf5e492781f806eca787abbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1189, Perplexity: 8.32, Token Acc: 35.39%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e4cc30dcb24f4ba05a1ab7a470b20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 70/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 70/300 - Train Loss: 2.2262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641c3bb827394599b4a12471d73b0d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1169, Perplexity: 8.31, Token Acc: 35.29%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch70.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a57ae3453c4221a7c45430a121b9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 71/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 71/300 - Train Loss: 2.2245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7a97b7176e4482b22794e84dec2cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1149, Perplexity: 8.29, Token Acc: 35.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51e1fb063b243b08aedf9e731a849e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 72/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 72/300 - Train Loss: 2.2228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650e5d3846bb40b09b8beea09ec6b74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1116, Perplexity: 8.26, Token Acc: 35.59%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch72.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ddd201919a4e5b91c87efa8ee3a5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 73/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 73/300 - Train Loss: 2.2211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7025626101c84eb09273f4e52139134c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1098, Perplexity: 8.25, Token Acc: 35.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e73fab5f9d046519f2015ce43179fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 74/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 74/300 - Train Loss: 2.2192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0773a49b754b139b993b5efaddd916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1070, Perplexity: 8.22, Token Acc: 35.67%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch74.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7dbd65718b49fc901fb4663ff4cb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 75/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 75/300 - Train Loss: 2.2167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cc5b041c5546048b9d5f4dab45ec09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1049, Perplexity: 8.21, Token Acc: 35.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793156338a0a4237bb2d1b032ab1612e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 76/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 76/300 - Train Loss: 2.2156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a21478624c46f0aefb56c3c37f0565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.1035, Perplexity: 8.19, Token Acc: 35.64%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch76.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b44176e2eb402e9ebed91013bcf8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 77/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 77/300 - Train Loss: 2.2128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db28e18657bc4fd48e17dc57ce560ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0999, Perplexity: 8.17, Token Acc: 35.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d670e84482346cbabf43f2e7d7a123e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 78/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 78/300 - Train Loss: 2.2114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe96f63ba69749a3a60bc3762e090a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0990, Perplexity: 8.16, Token Acc: 35.76%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch78.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f055348232472fa441d693be309cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 79/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 79/300 - Train Loss: 2.2100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd10d65729304258bdb97f69e75881b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0967, Perplexity: 8.14, Token Acc: 35.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb83cde6bdd64fe4a08d60df5abe8da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 80/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 80/300 - Train Loss: 2.2085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b88f816d5d4b759fd8a8f726e7a900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0931, Perplexity: 8.11, Token Acc: 36.01%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch80.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e46d7493a144bd9a70ffcddf9a232ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 81/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 81/300 - Train Loss: 2.2061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f9ad39600242e19fe73e29a74e3ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0905, Perplexity: 8.09, Token Acc: 36.11%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b455410c97b64492a4e0a7727ede4e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 82/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 82/300 - Train Loss: 2.2037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4808551d3f624243b40c3a63cd47d2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0887, Perplexity: 8.07, Token Acc: 36.16%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch82.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848c755f1bec4a87897ba9f99d4dbf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 83/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 83/300 - Train Loss: 2.2018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1464c8b60502457ea8a6a213d746c4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0851, Perplexity: 8.05, Token Acc: 36.23%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dbdfc32a5e41d3a6453d740b2c42dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 84/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 84/300 - Train Loss: 2.1988\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84258fce523f431e93eac9e8543c0427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0833, Perplexity: 8.03, Token Acc: 36.23%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch84.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d2ab5f5bad4f57a7172b5253861878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 85/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 85/300 - Train Loss: 2.1982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e656c75a8ef49a890bd89d863960ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0811, Perplexity: 8.01, Token Acc: 36.30%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6000a61e82467499eba174541df963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 86/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 86/300 - Train Loss: 2.1960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4f1ac9257c4e138731222a7334f2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0792, Perplexity: 8.00, Token Acc: 36.39%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch86.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93c5241358e4f93bb8875284d9f9bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 87/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 87/300 - Train Loss: 2.1942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314d0e1683214417bcd42bdc0126411b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0778, Perplexity: 7.99, Token Acc: 36.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b406b5d876643c98bf0d32e2f5339df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 88/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 88/300 - Train Loss: 2.1921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1ef68691fc47d1a9fda38507a923f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0743, Perplexity: 7.96, Token Acc: 36.54%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch88.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0219669c6ade4af5b4b3f97ae53443b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 89/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 89/300 - Train Loss: 2.1902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89daff9992f2445b8a5d15ac282b4158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0722, Perplexity: 7.94, Token Acc: 36.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70d512573104ff0b47c7428a67abbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 90/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 90/300 - Train Loss: 2.1882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53e5b7dcf4d49cdac16d313d12a8892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0703, Perplexity: 7.93, Token Acc: 36.53%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch90.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee97909334ee4304aa2a48eef746d276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 91/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 91/300 - Train Loss: 2.1877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59893b0d18b4863a6ee6e0fa2f4820f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0675, Perplexity: 7.90, Token Acc: 36.71%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce954e0e114b4d5e97400e5b0ceb2484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 92/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 92/300 - Train Loss: 2.1844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0543e34916ca4211b0cfa12e9e022ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0651, Perplexity: 7.89, Token Acc: 36.83%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch92.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84cbeb277a640599d5d04552aaa7a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 93/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 93/300 - Train Loss: 2.1837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bd407c9e304c399505e6bc8f9e8f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0640, Perplexity: 7.88, Token Acc: 36.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9124975812d4a47861a6eb0659957f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 94/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 94/300 - Train Loss: 2.1815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cf25df1a9c4c24acd22aa2baf704d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0629, Perplexity: 7.87, Token Acc: 36.79%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch94.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a73a21e911b46c59384878917ea056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 95/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 95/300 - Train Loss: 2.1814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5ff19c13744306a5a7709ea6bbc596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0611, Perplexity: 7.85, Token Acc: 36.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1224e47e449e4b6ca30af2ad492548e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 96/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 96/300 - Train Loss: 2.1796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b4599ebe5e4c37900a94d8a0c8f125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0598, Perplexity: 7.84, Token Acc: 36.83%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch96.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a5d9e4e80348b992d0e3ab73acc7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 97/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 97/300 - Train Loss: 2.1774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b766127a7453437c866e070f02258bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0582, Perplexity: 7.83, Token Acc: 36.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2e565a4c2743e7ba62e87939348981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 98/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 98/300 - Train Loss: 2.1751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c92ea249bf64985a87b4a14ee015d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0543, Perplexity: 7.80, Token Acc: 37.01%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch98.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edd5ae2564e4f6e96aa36388b41c5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 99/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 99/300 - Train Loss: 2.1746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d054b6f32347d0ba8781f2cee7d336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0534, Perplexity: 7.79, Token Acc: 37.14%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb21935030b4f8ca7e0f588cc6be717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 100/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 100/300 - Train Loss: 2.1734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19269f37872450fadc45eb4546397a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0539, Perplexity: 7.80, Token Acc: 36.97%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch100.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c1174ebb2d43178d39388eb5eb74df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 101/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 101/300 - Train Loss: 2.1719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beafe887585f413ba32b00cb6932f8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0505, Perplexity: 7.77, Token Acc: 37.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75c869867d049eb88ee2de5cd27c8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 102/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 102/300 - Train Loss: 2.1708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b9810c010f4462bac931608f1b14a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0489, Perplexity: 7.76, Token Acc: 37.19%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch102.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4b4717c0dd4f488a195cca7c8c51fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 103/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 103/300 - Train Loss: 2.1685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c531dbdab4651adf1a56b0f7b01e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0480, Perplexity: 7.75, Token Acc: 37.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1f7b7f43534f8d9bd687722fe604ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 104/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 104/300 - Train Loss: 2.1667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc80950079f4f4f9140cd029ebb2fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0470, Perplexity: 7.74, Token Acc: 37.08%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch104.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66ac3f98ee94bfaaabf38f4a6ef4c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 105/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 105/300 - Train Loss: 2.1664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78f11d4cd9342c49fb4d51f3a9943f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0458, Perplexity: 7.74, Token Acc: 37.30%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2594426e024fdb8a077f2bc9eedf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 106/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 106/300 - Train Loss: 2.1658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5fa455b7f94648a6c3072fd9b34ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0442, Perplexity: 7.72, Token Acc: 37.14%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch106.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c915037f1e8b42e79288ed2823c977a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 107/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 107/300 - Train Loss: 2.1632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b679d901ffae461b85a2c8d5b415111d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0427, Perplexity: 7.71, Token Acc: 37.30%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba58e6cbf6394a2aa987daa9c3749785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 108/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 108/300 - Train Loss: 2.1620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581fe17685dc490498df333f5ffe6369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0427, Perplexity: 7.71, Token Acc: 37.17%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch108.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad45941c5734abf8e3792b9e859e4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 109/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 109/300 - Train Loss: 2.1620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89b45c9557149beb1f650bdb791de54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0401, Perplexity: 7.69, Token Acc: 37.37%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7186e45b5cd44bbb6501f3e3549837e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 110/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 110/300 - Train Loss: 2.1596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f3237d3c0d4ce0b099569d9ab21fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0394, Perplexity: 7.69, Token Acc: 37.18%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch110.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fc4be55d9d488e9aa05efaec02ef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 111/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 111/300 - Train Loss: 2.1586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4486c8f979f143b1a2ee3cd9daa1aa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0369, Perplexity: 7.67, Token Acc: 37.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd8a04b22104c6eae5d615d88093f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 112/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 112/300 - Train Loss: 2.1576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fce339907740e8bb9a3895c9282844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0379, Perplexity: 7.67, Token Acc: 37.31%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch112.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00111b4771df4e188197adcdeb6de009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 113/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 113/300 - Train Loss: 2.1572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21b884223d448c8b165f492375411de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0354, Perplexity: 7.66, Token Acc: 37.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040e8f88cb974150a137cd31aa5b9f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 114/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 114/300 - Train Loss: 2.1556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573746fc6acc4dc7a6a599fca54d6f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0337, Perplexity: 7.64, Token Acc: 37.39%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch114.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdcbefae27749ef884353f2a5ca5270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 115/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 115/300 - Train Loss: 2.1541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a1f700515645629aebb14db48c842a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0329, Perplexity: 7.64, Token Acc: 37.54%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299b7317b8b04c8ea844da3dece4a3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 116/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 116/300 - Train Loss: 2.1527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463eb20731c14ffba5044e1bfe25bc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0312, Perplexity: 7.62, Token Acc: 37.49%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch116.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e320c473a34623a1c0f55bf98e02e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 117/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 117/300 - Train Loss: 2.1524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95ccf40f9994194bf86dfa2da986ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0292, Perplexity: 7.61, Token Acc: 37.72%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a39c5702e2a4e1ea72e809cb14cd23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 118/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 118/300 - Train Loss: 2.1507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1b8b6967b84beba172615b6062be2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0287, Perplexity: 7.60, Token Acc: 37.59%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch118.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9d8306f716409daf0c23b6632930a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 119/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 119/300 - Train Loss: 2.1498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bda89ec53f41cebc14d44a0bb285a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0270, Perplexity: 7.59, Token Acc: 37.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a73989e869940a28123e5e177260072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 120/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 120/300 - Train Loss: 2.1483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9afde1e00f4db7b768d5403218f5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0269, Perplexity: 7.59, Token Acc: 37.61%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch120.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6041495860ef41f5ab278e77f042f4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 121/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 121/300 - Train Loss: 2.1477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d913563955b4464c9abdcdd10faa2cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0259, Perplexity: 7.58, Token Acc: 37.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3449ad58e01a4d7da2756d8869b2c857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 122/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 122/300 - Train Loss: 2.1463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eced522926714cacafe2aa22646288ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0244, Perplexity: 7.57, Token Acc: 37.67%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch122.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d847e418984542848913bae7f3ce07bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 123/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 123/300 - Train Loss: 2.1466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6604118019bf413e9e02330a0c743c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0229, Perplexity: 7.56, Token Acc: 37.72%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cf25732e154235ab4f2da87c8598cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 124/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 124/300 - Train Loss: 2.1457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf6b2fb820f41de964ff3a3b31eaf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0218, Perplexity: 7.55, Token Acc: 37.83%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch124.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eb445ff7114d748fd1f179c76baf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 125/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 125/300 - Train Loss: 2.1431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8271a75d244e31b98ccfbda56de8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0199, Perplexity: 7.54, Token Acc: 37.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5431cfb4a0d741d6af04166d34811436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 126/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 126/300 - Train Loss: 2.1436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5e379ec92140238f45b55ba12717a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0201, Perplexity: 7.54, Token Acc: 37.85%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch126.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f9c2c6c901428e91e5dc9c1f1815c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 127/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 127/300 - Train Loss: 2.1429\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eda00db9efb426aa34adfa2a88d9259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0204, Perplexity: 7.54, Token Acc: 37.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c03135117f74a34bdca1a004c1f2a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 128/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 128/300 - Train Loss: 2.1409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7adbb3583ad46b596edae28e5f97ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0189, Perplexity: 7.53, Token Acc: 37.95%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch128.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948c4dea244340cfb09699e80c648632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 129/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 129/300 - Train Loss: 2.1395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e4e81756864292a9e1ed97199cba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0150, Perplexity: 7.50, Token Acc: 38.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ce2bf5a5f54d80a4924451b1b5d2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 130/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 130/300 - Train Loss: 2.1390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944a22ab1501437aa8b7a90cd3a5d6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0155, Perplexity: 7.50, Token Acc: 38.00%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch130.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d398567f2c142d0930bc5f5e7492073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 131/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 131/300 - Train Loss: 2.1387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034033a336c943b0bdcf8f545ac6c756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0134, Perplexity: 7.49, Token Acc: 38.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202663c6912746d197e8478bdeed0268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 132/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 132/300 - Train Loss: 2.1378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c208c42349415eabb6419f488eac86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0143, Perplexity: 7.50, Token Acc: 38.00%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch132.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4333e04b50b14375a46b0e9cd256721e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 133/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 133/300 - Train Loss: 2.1362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572e7e95e9dc4de5a868431b9d2c4437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0130, Perplexity: 7.49, Token Acc: 38.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9ebf93413f4cabbdf2d5f626dd89e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 134/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 134/300 - Train Loss: 2.1361\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37d83af718e4d278926814931b0e3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0127, Perplexity: 7.48, Token Acc: 38.12%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch134.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3e02a2b12d481ab153ea1f176340e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 135/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 135/300 - Train Loss: 2.1341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75e6d9f11b141b29bed32d9e32a8e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0105, Perplexity: 7.47, Token Acc: 38.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58be52a1ce254d96a10f0228b076a9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 136/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 136/300 - Train Loss: 2.1352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac029c1c6204baca090372a99a69fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0108, Perplexity: 7.47, Token Acc: 38.23%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch136.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0d4528a7bc474e995750b27ef66d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 137/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 137/300 - Train Loss: 2.1324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0311bd2aba7d4fd7b546fa19af8e8d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0080, Perplexity: 7.45, Token Acc: 38.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e26af9a7c647da9c0d90bf6915aacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 138/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 138/300 - Train Loss: 2.1319\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725253aacbb84ce8afd6ed8cc9da6701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0066, Perplexity: 7.44, Token Acc: 38.33%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch138.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c8e15cb65541908717a9ee53b3ead5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 139/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 139/300 - Train Loss: 2.1309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48b07db3381410b948cfe92172eba95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0067, Perplexity: 7.44, Token Acc: 38.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bbd49df36541e196ed34297e339d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 140/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 140/300 - Train Loss: 2.1306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d7262338d74189b7cb5a4a190f661a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0059, Perplexity: 7.43, Token Acc: 38.36%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch140.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f32b6ac7b6e4ad3b1a7e739a5ac3a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 141/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 141/300 - Train Loss: 2.1307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516f19e71c1e43728b6f077cad1a9bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0045, Perplexity: 7.42, Token Acc: 38.29%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe969f7ccddf47deb841538036fd5f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 142/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 142/300 - Train Loss: 2.1293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b211765691846129f5fc89b78a99756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0057, Perplexity: 7.43, Token Acc: 38.29%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch142.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c14d9fdcee4ac59ebbf7a0f1ca6610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 143/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 143/300 - Train Loss: 2.1294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0af5c89506f42d8a252d8b0a6ef29fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0044, Perplexity: 7.42, Token Acc: 38.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dbe5205a54466c81968787fc202eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 144/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 144/300 - Train Loss: 2.1284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087fb7fac7d249d6959a5517b01b8b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0037, Perplexity: 7.42, Token Acc: 38.44%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch144.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a93bf3c5c24fbea3b38f23353fd262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 145/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 145/300 - Train Loss: 2.1274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41cb119bb3f45b18620337f4a499ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0019, Perplexity: 7.40, Token Acc: 38.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5136ffb720214fb28945ddb80fcdbe92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 146/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 146/300 - Train Loss: 2.1251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5665debf65134defaa8b209ddab00e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0006, Perplexity: 7.39, Token Acc: 38.43%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch146.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2f103865c7495ab1237beca868725d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 147/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 147/300 - Train Loss: 2.1262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7935cdcdafb47e9b1886353be83431a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0004, Perplexity: 7.39, Token Acc: 38.39%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c296473d7c4fc2a228c4b0e60ff34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 148/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 148/300 - Train Loss: 2.1253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10884c3912494d24b0cafbefa1fdccb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 2.0005, Perplexity: 7.39, Token Acc: 38.40%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch148.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7c61faef86443a841cb09ec766098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 149/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 149/300 - Train Loss: 2.1253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820e83a28e5947389616411f825027c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9998, Perplexity: 7.39, Token Acc: 38.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75d768c192d4cc79cc9450c1455fa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 150/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 150/300 - Train Loss: 2.1232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ad50f50d3e4567859ff041fafed087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9972, Perplexity: 7.37, Token Acc: 38.51%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch150.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c363ac615574571b66c2dcbbc706694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 151/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 151/300 - Train Loss: 2.1215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d848ece06c8246339713fc9342b3044e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9981, Perplexity: 7.37, Token Acc: 38.43%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c685d6abc82e4e7e9fc62f70ac96bb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 152/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 152/300 - Train Loss: 2.1213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff973f0366b4f5b9eb72ad53f3d9792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9973, Perplexity: 7.37, Token Acc: 38.60%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch152.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635d0934ed4a46879936cbd67ee62a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 153/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 153/300 - Train Loss: 2.1219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16013fa17d294bef801c493aad581d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9953, Perplexity: 7.35, Token Acc: 38.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7754483176e746b1800aaf0257c53052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 154/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 154/300 - Train Loss: 2.1205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad654f34400748698ab3c96593896a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9941, Perplexity: 7.35, Token Acc: 38.52%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch154.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382d7f1a789a4679a5540a046c0543cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 155/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 155/300 - Train Loss: 2.1201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29055790f5d4ad4b2191eb448815621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9940, Perplexity: 7.35, Token Acc: 38.53%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd64426cca8c449585131138d988d20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 156/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 156/300 - Train Loss: 2.1194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa46394f53741e6afe47f7312792781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9934, Perplexity: 7.34, Token Acc: 38.60%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch156.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0deae612f10944b092aede45fad98f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 157/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 157/300 - Train Loss: 2.1190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560fe8af7dbf4a5783878076690fcb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9922, Perplexity: 7.33, Token Acc: 38.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75401eef8dc344f1aa23222dd6d1f2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 158/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 158/300 - Train Loss: 2.1187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672f07ed67c241fb99f508a960571591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9904, Perplexity: 7.32, Token Acc: 38.79%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch158.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384e1c5aaebb45009d2fdfc6ae539b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 159/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 159/300 - Train Loss: 2.1166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dee9ff389a5429095a728c1436723a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9899, Perplexity: 7.31, Token Acc: 38.57%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9bece1654b4efb9b98bf487d0b8c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 160/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 160/300 - Train Loss: 2.1176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043c9a1f45a4465992252fd1dc86d105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9891, Perplexity: 7.31, Token Acc: 38.74%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch160.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20df8b46a97b44f98d834ba246f2577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 161/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 161/300 - Train Loss: 2.1164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5d8c09b8594d6a8002b5364eae4bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9898, Perplexity: 7.31, Token Acc: 38.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ebf03adc2745b0a269c296364af395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 162/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 162/300 - Train Loss: 2.1141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86175c01843e4804aec4f142b5e6586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9865, Perplexity: 7.29, Token Acc: 38.96%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch162.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d42dbc213547129f0ce7cb777a946e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 163/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 163/300 - Train Loss: 2.1148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ae19adec3a431d8d7525832b1ffdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9872, Perplexity: 7.30, Token Acc: 38.71%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768e7a90ca804420b93437728f9eb119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 164/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 164/300 - Train Loss: 2.1142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945c3b6b747146a797abb657cd0e1a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9857, Perplexity: 7.28, Token Acc: 38.91%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch164.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb7ba027ef945309e991793a4942882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 165/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 165/300 - Train Loss: 2.1129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a11b3dd4e846019fbc70ae1b4be583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9858, Perplexity: 7.28, Token Acc: 38.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151274f9885442598d752098fd3b1d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 166/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 166/300 - Train Loss: 2.1130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9f95119ab54c60a67f4d8702ee536e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9867, Perplexity: 7.29, Token Acc: 38.68%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch166.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fae021926d54f12923fde1bb27cd0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 167/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 167/300 - Train Loss: 2.1125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce177d653fb44dcaac12d5e9137e6aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9842, Perplexity: 7.27, Token Acc: 38.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3e70e887a64ee2946105e25cba6e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 168/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 168/300 - Train Loss: 2.1115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e8455ccb4e43b1849f2cda0e692c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9826, Perplexity: 7.26, Token Acc: 38.91%\n",
      "✅ Saved checkpoint: checkpoints/blt_epoch168.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e410036ec104bfaa87042de0e1253f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 169/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 169/300 - Train Loss: 2.1119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9299850057504dde8118c1f59eeb99ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Validation - Loss: 1.9833, Perplexity: 7.27, Token Acc: 38.86%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959332dfe63d4776a658b88cf820e2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 170/300 [Training]:   0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 170/300 - Train Loss: 2.1098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f03ab646c34ad997e0dba6da791e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      9\u001b[39m     torch.set_float32_matmul_precision(\u001b[33m\"\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m model = BLTModel(\n\u001b[32m     12\u001b[39m     vocab_size=\u001b[38;5;28mlen\u001b[39m(VOCAB), \n\u001b[32m     13\u001b[39m     d_model=\u001b[32m64\u001b[39m, \n\u001b[32m     14\u001b[39m     nhead=\u001b[32m4\u001b[39m, \n\u001b[32m     15\u001b[39m     dropout=\u001b[32m0.1\u001b[39m\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mtrain_blt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAVE_EVERY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# resume_path=\"checkpoints/blt_epoch.pt\"\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mtrain_blt\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, lr, device, save_every, resume_path)\u001b[39m\n\u001b[32m     65\u001b[39m avg_loss = total_loss / total_tokens \u001b[38;5;28;01mif\u001b[39;00m total_tokens > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📘 Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m val_loss, val_acc = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m perplexity = math.exp(val_loss) \u001b[38;5;28;01mif\u001b[39;00m val_loss < \u001b[32m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📗 Validation - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Perplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperplexity\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Token Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, val_loader, criterion, device)\u001b[39m\n\u001b[32m     92\u001b[39m tgt_out = tgt_padded[:, \u001b[32m1\u001b[39m:]\n\u001b[32m     93\u001b[39m tgt_pad_mask = (tgt_inp == PAD_IDX)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_pad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m loss = criterion(logits.reshape(-\u001b[32m1\u001b[39m, logits.shape[-\u001b[32m1\u001b[39m]), tgt_out.reshape(-\u001b[32m1\u001b[39m))\n\u001b[32m     98\u001b[39m total_loss += loss.item() * (tgt_out != PAD_IDX).sum().item() \u001b[38;5;66;03m# Count non-padded tokens for loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mBLTModel.forward\u001b[39m\u001b[34m(self, src_patches_batch, tgt_inp, tgt_pad_mask)\u001b[39m\n\u001b[32m     53\u001b[39m         sample_emb = torch.zeros(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.d_model, device=device)\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m         sample_emb = torch.stack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpatch_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m patch_list])\n\u001b[32m     56\u001b[39m     batch_embeddings.append(sample_emb)\n\u001b[32m     58\u001b[39m src_emb = pad_sequence(batch_embeddings, batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value=\u001b[32m0.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mPatchEmbedder.forward\u001b[39m\u001b[34m(self, patch)\u001b[39m\n\u001b[32m     28\u001b[39m         bucket = hash_ngram(ng, \u001b[38;5;28mself\u001b[39m.num_buckets)\n\u001b[32m     29\u001b[39m         idx = torch.tensor(bucket, dtype=torch.long, device=device)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         vectors.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vectors) == \u001b[32m0\u001b[39m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.zeros(\u001b[38;5;28mself\u001b[39m.embed_dim, device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/sparse.py:192\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:2546\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2540\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2542\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2543\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2545\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    LEARNING_RATE = 1e-4\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 300 \n",
    "    SAVE_EVERY = 2\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    if device.type == \"mps\":\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    model = BLTModel(\n",
    "        vocab_size=len(VOCAB), \n",
    "        d_model=64, \n",
    "        nhead=4, \n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "    train_blt(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        lr=LEARNING_RATE,\n",
    "        device=device,\n",
    "        save_every=SAVE_EVERY,\n",
    "        resume_path=None\n",
    "        # resume_path=\"checkpoints/blt_epoch.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3cfa26",
   "metadata": {},
   "source": [
    "## Testing and Validating BLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "306f8464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded checkpoint from epoch 168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f146939dec504f67b8fe458440cc855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🧪 Evaluating Test Set:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 📊 Final BLT Model Evaluation ---\n",
      "  - Final Train Loss:    2.1115 (from checkpoint)\n",
      "--------------------------------------\n",
      "  - Test Loss:           1.9690\n",
      "  - Test Token Accuracy: 39.03%\n",
      "  - Test Perplexity:     7.16\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Step 1: Define ALL necessary components from your training script ---\n",
    "# This makes the script runnable on its own.\n",
    "\n",
    "# Assume your core helper functions are defined here:\n",
    "# patchify, hash_ngram, extract_ngrams\n",
    "\n",
    "# Assume your model classes are defined here:\n",
    "# PatchEmbedder, PositionalEncoding, BLTModel\n",
    "\n",
    "# --- Step 2: The Simplified Evaluation Function ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_final_model(model_class, vocab_size, ckpt_path, test_loader, device):\n",
    "    \"\"\"\n",
    "    Loads a model from a checkpoint and evaluates it on the test set.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found at: {ckpt_path}\")\n",
    "\n",
    "    # --- Load Checkpoint and Model ---\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    \n",
    "    # Instantiate the model with the correct architecture\n",
    "    model = model_class(\n",
    "        vocab_size=vocab_size, \n",
    "        d_model=64, \n",
    "        nhead=4, \n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✅ Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    # --- Extract Metrics from Checkpoint ---\n",
    "    train_loss = checkpoint.get('loss', 'N/A') # .get is safer\n",
    "    \n",
    "    # --- Evaluation Loop ---\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    total_loss = 0.0\n",
    "    correct_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    progress_bar = tqdm(test_loader, desc=\"🧪 Evaluating Test Set\")\n",
    "    for src_patches, tgt_padded in progress_bar:\n",
    "        # Correctly handle the new data format\n",
    "        tgt_padded = tgt_padded.to(device)\n",
    "        tgt_inp = tgt_padded[:, :-1]\n",
    "        tgt_out = tgt_padded[:, 1:]\n",
    "        tgt_pad_mask = (tgt_inp == PAD_IDX)\n",
    "        \n",
    "        # Correctly call the model\n",
    "        logits = model(src_patches, tgt_inp, tgt_pad_mask)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = (tgt_out != PAD_IDX)\n",
    "        correct_tokens += ((preds == tgt_out) & mask).sum().item()\n",
    "        total_tokens += mask.sum().item()\n",
    "\n",
    "    # --- Calculate Final Metrics ---\n",
    "    avg_test_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100.0 * correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    perplexity = math.exp(avg_test_loss) if avg_test_loss < 100 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": avg_test_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"perplexity\": perplexity\n",
    "    }\n",
    "\n",
    "# --- Step 3: Main Execution Block ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Configuration ---\n",
    "    CHECKPOINT_PATH = \"checkpoints/blt_epoch168.pt\" # The final model to test\n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # --- Load Data ---\n",
    "    # You must have the test.csv file available\n",
    "    test_ds = BLTDataset(csv_path=\"./../data/test.csv\")\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=blt_collate_fn\n",
    "    )\n",
    "\n",
    "    # --- Run Evaluation ---\n",
    "    results = evaluate_final_model(\n",
    "        model_class=BLTModel,\n",
    "        vocab_size=len(VOCAB),\n",
    "        ckpt_path=CHECKPOINT_PATH,\n",
    "        test_loader=test_loader,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # --- Print a Clean Report ---\n",
    "    print(\"\\n--- 📊 Final BLT Model Evaluation ---\")\n",
    "    print(f\"  - Final Train Loss:    {results['train_loss']:.4f} (from checkpoint)\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(f\"  - Test Loss:           {results['test_loss']:.4f}\")\n",
    "    print(f\"  - Test Token Accuracy: {results['accuracy']:.2f}%\")\n",
    "    print(f\"  - Test Perplexity:     {results['perplexity']:.2f}\")\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fda4e",
   "metadata": {},
   "source": [
    "## Graphs and all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a0275dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Successfully Parsed Metrics ---\n",
      "   epoch  train_loss  val_loss  val_perplexity  val_accuracy\n",
      "0      1      2.9616    2.6513           14.17         21.77\n",
      "1      2      2.6379    2.5659           13.01         23.33\n",
      "2      3      2.5791    2.5193           12.42         24.34\n",
      "3      4      2.5480    2.4904           12.07         25.07\n",
      "4      5      2.5237    2.4670           11.79         25.63\n",
      "\n",
      "✅ Graphs saved to 'training_metrics_plot.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- User Configuration ---\n",
    "# Just change this to the name of your saved log file.\n",
    "LOG_FILE_PATH = \"training_log.txt\"\n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads the training log file and extracts metrics using regular expressions.\n",
    "    This is extremely fast as it does not load any models.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Regex to find the lines with our metrics\n",
    "    train_loss_regex = re.compile(r\"Epoch (\\d+)/\\d+ - Train Loss: ([\\d.]+)\")\n",
    "    val_metrics_regex = re.compile(r\"Validation - Loss: ([\\d.]+), Perplexity: ([\\d.]+), Token Acc: ([\\d.]+)%\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: The log file was not found at '{file_path}'\")\n",
    "        print(\"Please save your training output to this file and try again.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    epoch_data = {}\n",
    "    for line in lines:\n",
    "        train_match = train_loss_regex.search(line)\n",
    "        val_match = val_metrics_regex.search(line)\n",
    "\n",
    "        if train_match:\n",
    "            # When we find a new training loss, we start a new record\n",
    "            if epoch_data: # Save the previous epoch's complete data\n",
    "                metrics.append(epoch_data)\n",
    "            epoch_data = {\n",
    "                \"epoch\": int(train_match.group(1)),\n",
    "                \"train_loss\": float(train_match.group(2))\n",
    "            }\n",
    "        \n",
    "        if val_match and epoch_data:\n",
    "            # Add validation metrics to the current epoch's record\n",
    "            epoch_data[\"val_loss\"] = float(val_match.group(1))\n",
    "            epoch_data[\"val_perplexity\"] = float(val_match.group(2))\n",
    "            epoch_data[\"val_accuracy\"] = float(val_match.group(3))\n",
    "\n",
    "    if epoch_data: # Append the last record\n",
    "        metrics.append(epoch_data)\n",
    "        \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. Parse the log file to get the metrics DataFrame\n",
    "    metrics_df = parse_log_file(LOG_FILE_PATH)\n",
    "\n",
    "    if metrics_df.empty:\n",
    "        print(\"Could not extract any data. Please check the log file content and path.\")\n",
    "    else:\n",
    "        print(\"--- Successfully Parsed Metrics ---\")\n",
    "        print(metrics_df.head())\n",
    "\n",
    "        # 2. Plotting the results\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n",
    "        fig.suptitle('BLT Model Training Metrics', fontsize=16)\n",
    "\n",
    "        # Plot 1: Training vs. Validation Loss\n",
    "        sns.lineplot(data=metrics_df, x='epoch', y='train_loss', ax=axes[0], label='Training Loss', color='b', marker='o')\n",
    "        sns.lineplot(data=metrics_df, x='epoch', y='val_loss', ax=axes[0], label='Validation Loss', color='r', marker='o')\n",
    "        axes[0].set_title('Training vs. Validation Loss')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "\n",
    "        # Plot 2: Validation Token Accuracy\n",
    "        sns.lineplot(data=metrics_df, x='epoch', y='val_accuracy', ax=axes[1], color='g', marker='o')\n",
    "        axes[1].set_title('Validation Token Accuracy')\n",
    "        axes[1].set_ylabel('Accuracy (%)')\n",
    "\n",
    "        # Plot 3: Validation Perplexity\n",
    "        sns.lineplot(data=metrics_df, x='epoch', y='val_perplexity', ax=axes[2], color='purple', marker='o')\n",
    "        axes[2].set_title('Validation Perplexity')\n",
    "        axes[2].set_ylabel('Perplexity')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylim(bottom=1) # Perplexity is meaningless below 1\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        # Save the figure to a file\n",
    "        plt.savefig(\"training_metrics_plot.png\")\n",
    "        print(\"\\n✅ Graphs saved to 'training_metrics_plot.png'\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb7ca9",
   "metadata": {},
   "source": [
    "## Inference Function (Text-to-Text Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d22d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded checkpoint from epoch 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inference Result ---\n",
      "Input:  'reconciliation trolls realized scene'\n",
      "Output: 'sellicid seiretnoc seiral noitarep sellic seirac'\n",
      "Expected: 'enecs dezilaer sllort noitailicnocer'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Step 1: Define necessary components and vocabulary ---\n",
    "# This should be consistent with your training script.\n",
    "\n",
    "# Assume your helper functions (patchify) and model classes (BLTModel) are defined or imported.\n",
    "# Assume your vocabulary constants are also defined. For clarity, here they are again:\n",
    "PRINTABLE_ASCII = [chr(i) for i in range(32, 127)]\n",
    "VOCAB = ['<PAD>', '<SOS>', '<EOS>'] + PRINTABLE_ASCII\n",
    "CHAR_TO_IDX = {ch: i for i, ch in enumerate(VOCAB)}\n",
    "IDX_TO_CHAR = {i: ch for i, ch in enumerate(VOCAB)}\n",
    "PAD_IDX = CHAR_TO_IDX['<PAD>']\n",
    "SOS_IDX = CHAR_TO_IDX['<SOS>']\n",
    "EOS_IDX = CHAR_TO_IDX['<EOS>']\n",
    "\n",
    "\n",
    "# --- Step 2: The Corrected Generation Function ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_prediction(model, input_text, max_len=100, device=None):\n",
    "    \"\"\"\n",
    "    Generates a text-to-text prediction using the complete BLTModel.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 1. Prepare the input: The model expects a BATCH of patch lists.\n",
    "    #    For a single prediction, we create a batch of size 1.\n",
    "    patches = patchify(input_text)\n",
    "    src_patches_batch = [patches] # e.g., [['patch1', 'patch2']]\n",
    "\n",
    "    # 2. Start the decoding process with the Start-Of-Sequence token.\n",
    "    output_ids = [SOS_IDX]\n",
    "\n",
    "    # 3. Autoregressively generate the output sequence one token at a time.\n",
    "    for _ in range(max_len):\n",
    "        # Prepare the current sequence as the decoder's input\n",
    "        tgt_inp = torch.tensor([output_ids], dtype=torch.long, device=device)\n",
    "        tgt_pad_mask = (tgt_inp == PAD_IDX)\n",
    "\n",
    "        # >>> THE CRITICAL STEP <<<\n",
    "        # Call the full model. It will handle the patch embedding, encoder,\n",
    "        # global transformer, and decoder internally.\n",
    "        logits = model(src_patches_batch, tgt_inp, tgt_pad_mask)\n",
    "        \n",
    "        # 4. Get the next token using greedy decoding (picking the most likely one).\n",
    "        next_id = logits[:, -1, :].argmax().item()\n",
    "        \n",
    "        # 5. Append the new token and check if we should stop.\n",
    "        output_ids.append(next_id)\n",
    "        if next_id == EOS_IDX:\n",
    "            break\n",
    "            \n",
    "    # 6. Convert the final list of token IDs back to a string.\n",
    "    #    We skip the first token, which is the <SOS> token.\n",
    "    output_text = \"\".join([IDX_TO_CHAR.get(i, \"\") for i in output_ids[1:] if i != EOS_IDX])\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "\n",
    "# --- Step 3: Example Usage ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Load your final, trained model ---\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Instantiate the model with the correct vocab size\n",
    "    model = BLTModel(vocab_size=len(VOCAB), d_model=64, nhead=4)\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    ckpt_path = \"checkpoints/blt_epoch168.pt\" # IMPORTANT: Use your final checkpoint\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    print(f\"✅ Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    # --- Run Prediction ---\n",
    "    input_text = \"reconciliation trolls realized scene\"\n",
    "    output_text = generate_prediction(model, input_text, max_len=100, device=device)\n",
    "    \n",
    "    print(\"\\n--- Inference Result ---\")\n",
    "    print(f\"Input:  '{input_text}'\")\n",
    "    print(f\"Output: '{output_text}'\")\n",
    "    print(f\"Expected: '{input_text[::-1]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebaf1f",
   "metadata": {},
   "source": [
    "## Prediction on test data and saving CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Step 1: Define ALL necessary components from your training script ---\n",
    "# This makes the script runnable on its own.\n",
    "# You MUST paste your final, corrected versions of the following:\n",
    "#\n",
    "# 1. All helper functions (patchify, etc.)\n",
    "# 2. All vocabulary constants (VOCAB, CHAR_TO_IDX, IDX_TO_CHAR, PAD_IDX, SOS_IDX, EOS_IDX)\n",
    "# 3. The BLTDataset class\n",
    "# 4. The blt_collate_fn function\n",
    "# 5. The PatchEmbedder, PositionalEncoding, and BLTModel classes\n",
    "\n",
    "# --- Step 2: A Batch-Oriented Generation Function (Much Faster) ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_batch_predictions(model, data_loader, max_len=100, device=None):\n",
    "    \"\"\"\n",
    "    Generates predictions for an entire DataLoader in batches for efficiency.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    progress_bar = tqdm(data_loader, desc=\"🚀 Generating Predictions\")\n",
    "\n",
    "    for src_patches_batch, _ in progress_bar:\n",
    "        batch_size = len(src_patches_batch)\n",
    "        \n",
    "        # Start the decoding process for the whole batch with the SOS token\n",
    "        output_ids = torch.full((batch_size, 1), SOS_IDX, dtype=torch.long, device=device)\n",
    "\n",
    "        # A flag to track which sequences in the batch are finished\n",
    "        finished = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            tgt_pad_mask = (output_ids == PAD_IDX)\n",
    "            \n",
    "            # Call the model once for the entire batch\n",
    "            logits = model(src_patches_batch, output_ids, tgt_pad_mask)\n",
    "            \n",
    "            # Get the next token for every sequence in the batch\n",
    "            next_ids = logits[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "            \n",
    "            # Append the new tokens to the sequences\n",
    "            output_ids = torch.cat([output_ids, next_ids], dim=1)\n",
    "            \n",
    "            # Update the 'finished' status for any sequence that just generated an EOS token\n",
    "            finished = finished | (next_ids.squeeze() == EOS_IDX)\n",
    "            \n",
    "            # If all sequences in the batch are finished, we can stop early\n",
    "            if finished.all():\n",
    "                break\n",
    "        \n",
    "        # Decode the generated ID sequences into text\n",
    "        for i in range(batch_size):\n",
    "            # Filter out special tokens\n",
    "            filtered_ids = [idx for idx in output_ids[i].tolist() if idx not in {SOS_IDX, EOS_IDX, PAD_IDX}]\n",
    "            pred_text = \"\".join([IDX_TO_CHAR.get(idx, \"\") for idx in filtered_ids])\n",
    "            all_predictions.append(pred_text)\n",
    "            \n",
    "    return all_predictions\n",
    "\n",
    "# --- Step 3: Main Execution Block ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Configuration ---\n",
    "    CHECKPOINT_PATH = \"checkpoints/blt_epoch300.pt\" # The final model to use\n",
    "    BATCH_SIZE = 16 # Much faster than batch_size=1\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    if device.type == \"mps\":\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    # --- Load Model ---\n",
    "    model = BLTModel(vocab_size=len(VOCAB), d_model=64, nhead=4)\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    print(f\"✅ Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    # --- Load Test Data ---\n",
    "    test_df = pd.read_csv(\"./../data/test.csv\")\n",
    "    test_ds = BLTDataset(csv_path=\"./../data/test.csv\")\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=blt_collate_fn\n",
    "    )\n",
    "\n",
    "    # --- Generate All Predictions ---\n",
    "    predictions = generate_batch_predictions(model, test_loader, max_len=150, device=device)\n",
    "\n",
    "    # --- Save Predictions in the Correct Format ---\n",
    "    # As per the assignment, the output file should have 'input' and 'output' columns.\n",
    "    output_df = pd.DataFrame({\n",
    "        'input': test_df['input'],\n",
    "        'output': predictions\n",
    "    })\n",
    "    \n",
    "    os.makedirs(\"predictions\", exist_ok=True)\n",
    "    output_path = \"predictions/predictions_BLT.csv\"\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Predictions saved to {output_path}\")\n",
    "    print(\"\\n--- Prediction Preview ---\")\n",
    "    print(output_df.head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e59d25",
   "metadata": {},
   "source": [
    "# Character level Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beebbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using MPS (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ MPS not available, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d808956",
   "metadata": {},
   "source": [
    "## Data & Tokenizer\n",
    "\n",
    "1. Loads your train.csv and test.csv.\n",
    "2. Creates a character vocabulary:\n",
    "    - [PAD], [SOS], [EOS] + printable ASCII chars.\n",
    "    - Maps chars ↔ IDs (stoi, itos).\n",
    "3. Provides encode/decode functions.\n",
    "4. Tests it on a sample string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10000, 2)\n",
      "Test shape: (2000, 2)\n",
      "                                               input  \\\n",
      "0               reconciliation trolls realized scene   \n",
      "1                        scratched kemp blah devices   \n",
      "2  delusional engineered perfect prey englishman ...   \n",
      "3  boomers nfl reacts parallels everything 6 redu...   \n",
      "4  patience put christmas superhero luc rake fulf...   \n",
      "\n",
      "                                              target  \n",
      "0               enecs dezilaer sllort noitailicnocer  \n",
      "1                        secived halb pmek dehctarcs  \n",
      "2  hctarcs detsub namhsilgne yerp tcefrep dereeni...  \n",
      "3  stcudnoc ysereh redlof secuder 6 gnihtyreve sl...  \n",
      "4  ylesned ylno elbats latnenitnoc dellifluf ekar...  \n",
      "\n",
      "Vocab size: 98\n",
      "PAD idx: 0 SOS idx: 1 EOS idx: 2\n",
      "Sample: LMA is fun!\n",
      "Encoded: [1, 47, 48, 36, 3, 76, 86, 3, 73, 88, 81, 4, 2]\n",
      "Decoded: LMA is fun!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import string\n",
    "\n",
    "# --- Step 1: Load Data ---\n",
    "train_df = pd.read_csv(\"./../data/train.csv\")\n",
    "test_df  = pd.read_csv(\"./../data/test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(train_df.head())\n",
    "\n",
    "# --- Step 2: Character Tokenizer ---\n",
    "# Printable ASCII characters 32–126\n",
    "ascii_chars = [chr(i) for i in range(32, 127)]\n",
    "special_tokens = [\"[PAD]\", \"[SOS]\", \"[EOS]\"]\n",
    "\n",
    "itos = special_tokens + ascii_chars   # id → char\n",
    "stoi = {ch: i for i, ch in enumerate(itos)}  # char → id\n",
    "\n",
    "PAD_IDX = stoi[\"[PAD]\"]\n",
    "SOS_IDX = stoi[\"[SOS]\"]\n",
    "EOS_IDX = stoi[\"[EOS]\"]\n",
    "\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(\"\\nVocab size:\", vocab_size)\n",
    "print(\"PAD idx:\", PAD_IDX, \"SOS idx:\", SOS_IDX, \"EOS idx:\", EOS_IDX)\n",
    "\n",
    "# --- Encode / Decode functions ---\n",
    "def encode_text(text, add_special=True):\n",
    "    ids = [stoi[ch] for ch in text if ch in stoi]\n",
    "    if add_special:\n",
    "        ids = [SOS_IDX] + ids + [EOS_IDX]\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "def decode_ids(ids):\n",
    "    chars = []\n",
    "    for i in ids:\n",
    "        if i == PAD_IDX or i == SOS_IDX or i == EOS_IDX:\n",
    "            continue\n",
    "        chars.append(itos[i])\n",
    "    return \"\".join(chars)\n",
    "\n",
    "# --- Quick test ---\n",
    "sample = \"LMA is fun!\"\n",
    "encoded = encode_text(sample)\n",
    "decoded = decode_ids(encoded.tolist())\n",
    "\n",
    "print(\"Sample:\", sample)\n",
    "print(\"Encoded:\", encoded.tolist())\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7905ed",
   "metadata": {},
   "source": [
    "## Dataset + Collate\n",
    "\n",
    "- CharDataset → loads strings, encodes them into token IDs.\n",
    "- collate_fn → pads sequences per batch + stores lengths.\n",
    "- DataLoader → provides batches for training & testing.\n",
    "- Prints shapes and a decoded sample to check correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb46380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_padded shape: torch.Size([32, 132])\n",
      "tgt_padded shape: torch.Size([32, 132])\n",
      "\n",
      "src_lengths: tensor([67, 21, 80, 38, 67])\n",
      "tgt_lengths: tensor([67, 21, 80, 38, 67])\n",
      "\n",
      "Example decoded input: cam environments eventual fallen aug merchant garry quebec latter\n",
      "Example decoded target: rettal cebeuq yrrag tnahcrem gua nellaf lautneve stnemnorivne mac\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df[\"input\"].tolist()\n",
    "        self.targets = df[\"target\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.inputs[idx]\n",
    "        tgt_text = self.targets[idx]\n",
    "\n",
    "        src_ids = encode_text(src_text, add_special=True)  # [SOS] ... [EOS]\n",
    "        tgt_ids = encode_text(tgt_text, add_special=True)\n",
    "\n",
    "        return src_ids, tgt_ids\n",
    "\n",
    "\n",
    "# --- Collate Function ---\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "\n",
    "    # Pad sequences\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=PAD_IDX)\n",
    "    tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "    # Lengths (before padding)\n",
    "    src_lengths = torch.tensor([len(x) for x in src_batch], dtype=torch.long)\n",
    "    tgt_lengths = torch.tensor([len(x) for x in tgt_batch], dtype=torch.long)\n",
    "\n",
    "    return src_padded, src_lengths, tgt_padded, tgt_lengths\n",
    "\n",
    "\n",
    "# --- Create Dataset + DataLoader ---\n",
    "train_ds = CharDataset(train_df)\n",
    "test_ds = CharDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_df = pd.read_csv(\"./../data/test.csv\")  # original test dataset\n",
    "val_df, holdout_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "val_ds = CharDataset(val_df)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# --- Quick Check ---\n",
    "src_padded, src_lengths, tgt_padded, tgt_lengths = next(iter(train_loader))\n",
    "\n",
    "print(\"src_padded shape:\", src_padded.shape)\n",
    "print(\"tgt_padded shape:\", tgt_padded.shape)\n",
    "print(\"\\nsrc_lengths:\", src_lengths[:5])\n",
    "print(\"tgt_lengths:\", tgt_lengths[:5])\n",
    "print(\"\\nExample decoded input:\", decode_ids(src_padded[0].tolist()))\n",
    "print(\"Example decoded target:\", decode_ids(tgt_padded[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f9f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 98\n"
     ]
    }
   ],
   "source": [
    "# --- Character Vocabulary (printable ASCII + special tokens) ---\n",
    "import string\n",
    "\n",
    "PAD_IDX = 0\n",
    "SOS_IDX = 1\n",
    "EOS_IDX = 2\n",
    "\n",
    "# Printable ASCII characters (32-126)\n",
    "chars = [chr(i) for i in range(32, 127)]\n",
    "VOCAB = {c: i+3 for i, c in enumerate(chars)}  # reserve 0,1,2 for PAD, SOS, EOS\n",
    "INV_VOCAB = {i: c for c, i in VOCAB.items()}\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB) + 3  # include PAD, SOS, EOS\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09205993",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "- Embedding layer for characters\n",
    "- Positional encoding\n",
    "- Transformer encoder–decoder (2 layers each)\n",
    "- Linear projection to vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beadd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Positional Encoding (sinusoidal) ---\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, D]\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- Baseline Transformer Model ---\n",
    "class CharTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=64, nhead=4, num_layers=2, dim_ff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embeddings\n",
    "        self.src_embed = nn.Embedding(vocab_size, d_model, padding_idx=PAD_IDX)\n",
    "        self.tgt_embed = nn.Embedding(vocab_size, d_model, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                                    dim_feedforward=dim_ff, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers, enable_nested_tensor=False)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                                    dim_feedforward=dim_ff, dropout=dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output projection\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt_inp):\n",
    "        \"\"\"\n",
    "        src: [B, Ls]\n",
    "        tgt_inp: [B, Lt]\n",
    "        \"\"\"\n",
    "        # Embedding + positional encoding\n",
    "        src_emb = self.pos_encoder(self.src_embed(src))  # [B, Ls, D]\n",
    "        tgt_emb = self.pos_encoder(self.tgt_embed(tgt_inp))  # [B, Lt, D]\n",
    "\n",
    "        # Masks\n",
    "        src_key_padding_mask = (src == PAD_IDX)  # [B, Ls]\n",
    "        tgt_key_padding_mask = (tgt_inp == PAD_IDX)  # [B, Lt]\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(tgt_inp.size(1)).to(src.device)\n",
    "\n",
    "        # Encode\n",
    "        memory = self.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Decode\n",
    "        out = self.decoder(tgt=tgt_emb, memory=memory,\n",
    "                            tgt_mask=causal_mask,\n",
    "                            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                            memory_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Project to vocab\n",
    "        logits = self.fc_out(out)  # [B, Lt, vocab_size]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc2965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([32, 117, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "baseline_model = CharTransformer(vocab_size=len(VOCAB), d_model=64, nhead=4, num_layers=2).to(device)\n",
    "\n",
    "# Dummy batch\n",
    "src_padded, src_lengths, tgt_padded, tgt_lengths = next(iter(train_loader))\n",
    "\n",
    "# Teacher forcing: shift target\n",
    "tgt_inp = tgt_padded[:, :-1]\n",
    "tgt_out = tgt_padded[:, 1:]\n",
    "\n",
    "# Forward pass\n",
    "logits = baseline_model(src_padded.to(device), tgt_inp.to(device))\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)  # [B, Lt-1, vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf9a6b",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- AdamW optimizer\n",
    "- CrossEntropyLoss with ignore_index=PAD_IDX\n",
    "- Gradient clipping\n",
    "- Checkpoint saving every few epochs\n",
    "- Optional resume from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5949982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# ----------------------------\n",
    "# Training loop for baseline Transformer\n",
    "# ----------------------------\n",
    "def train_baseline(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader=None,   # optional validation loader\n",
    "    num_epochs=1000,\n",
    "    lr=1e-3,\n",
    "    device=None,\n",
    "    save_every=5,\n",
    "    val_every=50,\n",
    "    resume_path=None\n",
    "):\n",
    "    # --- Pick device automatically if not provided ---\n",
    "    if device is None:\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    print(f\"Training on: {device}\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)  # ignore <PAD> tokens\n",
    "\n",
    "    os.makedirs(\"checkpoints_baseline\", exist_ok=True)\n",
    "\n",
    "    # --- Resume from checkpoint ---\n",
    "    start_epoch = 1\n",
    "    if resume_path and os.path.exists(resume_path):\n",
    "        print(f\"🔄 Resuming from checkpoint: {resume_path}\")\n",
    "        checkpoint = torch.load(resume_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\"✅ Resumed from epoch {checkpoint['epoch']} (loss {checkpoint['loss']:.4f})\")\n",
    "\n",
    "    # --- Training loop ---\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            src, src_lengths, tgt, tgt_lengths = batch\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            tgt_inp = tgt[:, :-1]   # decoder input\n",
    "            tgt_out = tgt[:, 1:]    # expected output\n",
    "\n",
    "            logits = model(src, tgt_inp)\n",
    "\n",
    "            loss = criterion(\n",
    "                logits.reshape(-1, logits.size(-1)),\n",
    "                tgt_out.reshape(-1)\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # --- Validation ---\n",
    "        if val_loader is not None:\n",
    "            val_loss, val_acc = evaluate_baseline(model, val_loader, criterion, device)\n",
    "            val_perplexity = math.exp(val_loss)\n",
    "            print(f\"📘 Epoch {epoch}/{num_epochs} - Train Loss: {avg_loss:.4f}\")\n",
    "            print(f\"📗 Validation - Loss: {val_loss:.4f}, Perplexity: {val_perplexity:.2f}, Token Acc: {val_acc:.2f}%\")\n",
    "        else:\n",
    "            print(f\"📘 Epoch {epoch}/{num_epochs} - Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # --- Save checkpoint ---\n",
    "        if epoch % save_every == 0 or epoch == num_epochs:\n",
    "            ckpt_path = f\"checkpoints_baseline/char_transformer_epoch{epoch}.pt\"\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"loss\": avg_loss\n",
    "            }, ckpt_path)\n",
    "            print(f\"✅ Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation / Validation\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate_baseline(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        src, src_lengths, tgt, tgt_lengths = batch\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        tgt_inp = tgt[:, :-1]\n",
    "        tgt_out = tgt[:, 1:]\n",
    "\n",
    "        logits = model(src, tgt_inp)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt_out.reshape(-1)\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Accuracy (ignore PAD)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = tgt_out != PAD_IDX\n",
    "        correct_tokens += ((preds == tgt_out) & mask).sum().item()\n",
    "        total_tokens += mask.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = 100.0 * correct_tokens / total_tokens\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314938ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: mps\n",
      "🔄 Resuming from checkpoint: checkpoints_baseline/char_transformer_epoch470.pt\n",
      "✅ Resumed from epoch 470 (loss 0.0057)\n",
      "📘 Epoch 471/1000 - Train Loss: 0.0056\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 472/1000 - Train Loss: 0.0062\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.95%\n",
      "📘 Epoch 473/1000 - Train Loss: 0.0062\n",
      "📗 Validation - Loss: 0.0006, Perplexity: 1.00, Token Acc: 99.95%\n",
      "📘 Epoch 474/1000 - Train Loss: 0.0061\n",
      "📗 Validation - Loss: 0.0003, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 475/1000 - Train Loss: 0.0061\n",
      "📗 Validation - Loss: 0.0005, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 476/1000 - Train Loss: 0.0054\n",
      "📗 Validation - Loss: 0.0002, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 477/1000 - Train Loss: 0.0056\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 478/1000 - Train Loss: 0.0063\n",
      "📗 Validation - Loss: 0.0011, Perplexity: 1.00, Token Acc: 99.94%\n",
      "📘 Epoch 479/1000 - Train Loss: 0.0063\n",
      "📗 Validation - Loss: 0.0003, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 480/1000 - Train Loss: 0.0052\n",
      "📗 Validation - Loss: 0.0006, Perplexity: 1.00, Token Acc: 99.96%\n",
      "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch480.pt\n",
      "📘 Epoch 481/1000 - Train Loss: 0.0053\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 482/1000 - Train Loss: 0.0064\n",
      "📗 Validation - Loss: 0.0002, Perplexity: 1.00, Token Acc: 99.97%\n",
      "📘 Epoch 483/1000 - Train Loss: 0.0059\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 484/1000 - Train Loss: 0.0052\n",
      "📗 Validation - Loss: 0.0003, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 485/1000 - Train Loss: 0.0066\n",
      "📗 Validation - Loss: 0.0005, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 486/1000 - Train Loss: 0.0064\n",
      "📗 Validation - Loss: 0.0006, Perplexity: 1.00, Token Acc: 99.95%\n",
      "📘 Epoch 487/1000 - Train Loss: 0.0060\n",
      "📗 Validation - Loss: 0.0003, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 488/1000 - Train Loss: 0.0050\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 489/1000 - Train Loss: 0.0065\n",
      "📗 Validation - Loss: 0.0002, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 490/1000 - Train Loss: 0.0057\n",
      "📗 Validation - Loss: 0.0002, Perplexity: 1.00, Token Acc: 99.96%\n",
      "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch490.pt\n",
      "📘 Epoch 491/1000 - Train Loss: 0.0057\n",
      "📗 Validation - Loss: 0.0005, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 492/1000 - Train Loss: 0.0061\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.95%\n",
      "📘 Epoch 493/1000 - Train Loss: 0.0052\n",
      "📗 Validation - Loss: 0.0002, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 494/1000 - Train Loss: 0.0058\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 495/1000 - Train Loss: 0.0054\n",
      "📗 Validation - Loss: 0.0003, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 496/1000 - Train Loss: 0.0064\n",
      "📗 Validation - Loss: 0.0005, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 497/1000 - Train Loss: 0.0061\n",
      "📗 Validation - Loss: 0.0002, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 498/1000 - Train Loss: 0.0052\n",
      "📗 Validation - Loss: 0.0004, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 499/1000 - Train Loss: 0.0065\n",
      "📗 Validation - Loss: 0.0003, Perplexity: 1.00, Token Acc: 99.96%\n",
      "📘 Epoch 500/1000 - Train Loss: 0.0057\n",
      "📗 Validation - Loss: 0.0007, Perplexity: 1.00, Token Acc: 99.94%\n",
      "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch500.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mPYTORCH_ENABLE_MPS_FALLBACK\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrain_baseline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoints_baseline/char_transformer_epoch470.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mtrain_baseline\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, lr, device, save_every, val_every, resume_path)\u001b[39m\n\u001b[32m     67\u001b[39m     loss.backward()\n\u001b[32m     68\u001b[39m     clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     total_loss += loss.item()\n\u001b[32m     73\u001b[39m avg_loss = total_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/adam.py:517\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    515\u001b[39m         param.addcdiv_(exp_avg, denom)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     step = \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m     bias_correction1 = \u001b[32m1\u001b[39m - beta1**step\n\u001b[32m    520\u001b[39m     bias_correction2 = \u001b[32m1\u001b[39m - beta2**step\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:96\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "train_baseline(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=1000,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    "    save_every=10,\n",
    "    resume_path=\"checkpoints_baseline/char_transformer_epoch500.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da1f1f",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7261e",
   "metadata": {},
   "source": [
    "Training on: mps\n",
    "🔄 Resuming from checkpoint: checkpoints_baseline/char_transformer_epoch50.pt\n",
    "✅ Resumed from epoch 50 (loss 0.2597)\n",
    "📘 Epoch 51/1000 - Train Loss: 0.2541\n",
    "📘 Epoch 52/1000 - Train Loss: 0.2507\n",
    "📘 Epoch 53/1000 - Train Loss: 0.2461\n",
    "📘 Epoch 54/1000 - Train Loss: 0.2391\n",
    "📘 Epoch 55/1000 - Train Loss: 0.2377\n",
    "📘 Epoch 56/1000 - Train Loss: 0.2259\n",
    "📘 Epoch 57/1000 - Train Loss: 0.2206\n",
    "📘 Epoch 58/1000 - Train Loss: 0.2184\n",
    "📘 Epoch 59/1000 - Train Loss: 0.2203\n",
    "📘 Epoch 60/1000 - Train Loss: 0.2083\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch60.pt\n",
    "📘 Epoch 61/1000 - Train Loss: 0.2050\n",
    "📘 Epoch 62/1000 - Train Loss: 0.2049\n",
    "📘 Epoch 63/1000 - Train Loss: 0.1927\n",
    "📘 Epoch 64/1000 - Train Loss: 0.1986\n",
    "📘 Epoch 65/1000 - Train Loss: 0.1843\n",
    "📘 Epoch 66/1000 - Train Loss: 0.1815\n",
    "📘 Epoch 67/1000 - Train Loss: 0.1738\n",
    "📘 Epoch 68/1000 - Train Loss: 0.1757\n",
    "📘 Epoch 69/1000 - Train Loss: 0.1659\n",
    "📘 Epoch 70/1000 - Train Loss: 0.1662\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch70.pt\n",
    "📘 Epoch 71/1000 - Train Loss: 0.1609\n",
    "📘 Epoch 72/1000 - Train Loss: 0.1558\n",
    "📘 Epoch 73/1000 - Train Loss: 0.1553\n",
    "📘 Epoch 74/1000 - Train Loss: 0.1495\n",
    "📘 Epoch 75/1000 - Train Loss: 0.1385\n",
    "📘 Epoch 76/1000 - Train Loss: 0.1384\n",
    "📘 Epoch 77/1000 - Train Loss: 0.1372\n",
    "📘 Epoch 78/1000 - Train Loss: 0.1381\n",
    "📘 Epoch 79/1000 - Train Loss: 0.1260\n",
    "📘 Epoch 80/1000 - Train Loss: 0.1224\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch80.pt\n",
    "📘 Epoch 81/1000 - Train Loss: 0.1169\n",
    "📘 Epoch 82/1000 - Train Loss: 0.1102\n",
    "📘 Epoch 83/1000 - Train Loss: 0.1037\n",
    "📘 Epoch 84/1000 - Train Loss: 0.0933\n",
    "📘 Epoch 85/1000 - Train Loss: 0.0786\n",
    "📘 Epoch 86/1000 - Train Loss: 0.0637\n",
    "📘 Epoch 87/1000 - Train Loss: 0.0627\n",
    "📘 Epoch 88/1000 - Train Loss: 0.0563\n",
    "📘 Epoch 89/1000 - Train Loss: 0.0493\n",
    "📘 Epoch 90/1000 - Train Loss: 0.0476\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch90.pt\n",
    "📘 Epoch 91/1000 - Train Loss: 0.0438\n",
    "📘 Epoch 92/1000 - Train Loss: 0.0410\n",
    "📘 Epoch 93/1000 - Train Loss: 0.0381\n",
    "📘 Epoch 94/1000 - Train Loss: 0.0376\n",
    "📘 Epoch 95/1000 - Train Loss: 0.0350\n",
    "📘 Epoch 96/1000 - Train Loss: 0.0354\n",
    "📘 Epoch 97/1000 - Train Loss: 0.0362\n",
    "📘 Epoch 98/1000 - Train Loss: 0.0319\n",
    "📘 Epoch 99/1000 - Train Loss: 0.0318\n",
    "📘 Epoch 100/1000 - Train Loss: 0.0310\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch100.pt\n",
    "📘 Epoch 101/1000 - Train Loss: 0.0312\n",
    "📘 Epoch 102/1000 - Train Loss: 0.0310\n",
    "📘 Epoch 103/1000 - Train Loss: 0.0307\n",
    "📘 Epoch 104/1000 - Train Loss: 0.0289\n",
    "📘 Epoch 105/1000 - Train Loss: 0.0290\n",
    "📘 Epoch 106/1000 - Train Loss: 0.0297\n",
    "📘 Epoch 107/1000 - Train Loss: 0.0274\n",
    "📘 Epoch 108/1000 - Train Loss: 0.0282\n",
    "📘 Epoch 109/1000 - Train Loss: 0.0267\n",
    "📘 Epoch 110/1000 - Train Loss: 0.0272\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch110.pt\n",
    "📘 Epoch 111/1000 - Train Loss: 0.0267\n",
    "📘 Epoch 112/1000 - Train Loss: 0.0264\n",
    "📘 Epoch 113/1000 - Train Loss: 0.0253\n",
    "📘 Epoch 114/1000 - Train Loss: 0.0256\n",
    "📘 Epoch 115/1000 - Train Loss: 0.0245\n",
    "📘 Epoch 116/1000 - Train Loss: 0.0250\n",
    "📘 Epoch 117/1000 - Train Loss: 0.0255\n",
    "📘 Epoch 118/1000 - Train Loss: 0.0250\n",
    "📘 Epoch 119/1000 - Train Loss: 0.0243\n",
    "📘 Epoch 120/1000 - Train Loss: 0.0230\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch120.pt\n",
    "📘 Epoch 121/1000 - Train Loss: 0.0239\n",
    "📘 Epoch 122/1000 - Train Loss: 0.0231\n",
    "📘 Epoch 123/1000 - Train Loss: 0.0225\n",
    "📘 Epoch 124/1000 - Train Loss: 0.0240\n",
    "📘 Epoch 125/1000 - Train Loss: 0.0229\n",
    "📘 Epoch 126/1000 - Train Loss: 0.0230\n",
    "📘 Epoch 127/1000 - Train Loss: 0.0211\n",
    "📘 Epoch 128/1000 - Train Loss: 0.0224\n",
    "📘 Epoch 129/1000 - Train Loss: 0.0209\n",
    "📘 Epoch 130/1000 - Train Loss: 0.0223\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch130.pt\n",
    "📘 Epoch 131/1000 - Train Loss: 0.0201\n",
    "📘 Epoch 132/1000 - Train Loss: 0.0226\n",
    "📘 Epoch 133/1000 - Train Loss: 0.0220\n",
    "📘 Epoch 134/1000 - Train Loss: 0.0210\n",
    "📘 Epoch 135/1000 - Train Loss: 0.0196\n",
    "📘 Epoch 136/1000 - Train Loss: 0.0196\n",
    "📘 Epoch 137/1000 - Train Loss: 0.0206\n",
    "📘 Epoch 138/1000 - Train Loss: 0.0202\n",
    "📘 Epoch 139/1000 - Train Loss: 0.0196\n",
    "📘 Epoch 140/1000 - Train Loss: 0.0183\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch140.pt\n",
    "📘 Epoch 141/1000 - Train Loss: 0.0211\n",
    "📘 Epoch 142/1000 - Train Loss: 0.0195\n",
    "📘 Epoch 143/1000 - Train Loss: 0.0204\n",
    "📘 Epoch 144/1000 - Train Loss: 0.0193\n",
    "📘 Epoch 145/1000 - Train Loss: 0.0197\n",
    "📘 Epoch 146/1000 - Train Loss: 0.0180\n",
    "📘 Epoch 147/1000 - Train Loss: 0.0195\n",
    "📘 Epoch 148/1000 - Train Loss: 0.0204\n",
    "📘 Epoch 149/1000 - Train Loss: 0.0177\n",
    "📘 Epoch 150/1000 - Train Loss: 0.0187\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch150.pt\n",
    "📘 Epoch 151/1000 - Train Loss: 0.0198\n",
    "📘 Epoch 152/1000 - Train Loss: 0.0182\n",
    "📘 Epoch 153/1000 - Train Loss: 0.0183\n",
    "📘 Epoch 154/1000 - Train Loss: 0.0178\n",
    "📘 Epoch 155/1000 - Train Loss: 0.0183\n",
    "📘 Epoch 156/1000 - Train Loss: 0.0183\n",
    "📘 Epoch 157/1000 - Train Loss: 0.0181\n",
    "📘 Epoch 158/1000 - Train Loss: 0.0160\n",
    "📘 Epoch 159/1000 - Train Loss: 0.0184\n",
    "📘 Epoch 160/1000 - Train Loss: 0.0172\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch160.pt\n",
    "📘 Epoch 161/1000 - Train Loss: 0.0181\n",
    "📘 Epoch 162/1000 - Train Loss: 0.0177\n",
    "📘 Epoch 163/1000 - Train Loss: 0.0169\n",
    "📘 Epoch 164/1000 - Train Loss: 0.0184\n",
    "📘 Epoch 165/1000 - Train Loss: 0.0167\n",
    "📘 Epoch 166/1000 - Train Loss: 0.0191\n",
    "📘 Epoch 167/1000 - Train Loss: 0.0171\n",
    "📘 Epoch 168/1000 - Train Loss: 0.0172\n",
    "📘 Epoch 169/1000 - Train Loss: 0.0172\n",
    "📘 Epoch 170/1000 - Train Loss: 0.0171\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch170.pt\n",
    "📘 Epoch 171/1000 - Train Loss: 0.0156\n",
    "📘 Epoch 172/1000 - Train Loss: 0.0165\n",
    "📘 Epoch 173/1000 - Train Loss: 0.0161\n",
    "📘 Epoch 174/1000 - Train Loss: 0.0177\n",
    "📘 Epoch 175/1000 - Train Loss: 0.0161\n",
    "📘 Epoch 176/1000 - Train Loss: 0.0166\n",
    "📘 Epoch 177/1000 - Train Loss: 0.0164\n",
    "📘 Epoch 178/1000 - Train Loss: 0.0157\n",
    "📘 Epoch 179/1000 - Train Loss: 0.0151\n",
    "📘 Epoch 180/1000 - Train Loss: 0.0152\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch180.pt\n",
    "📘 Epoch 181/1000 - Train Loss: 0.0155\n",
    "📘 Epoch 182/1000 - Train Loss: 0.0168\n",
    "📘 Epoch 183/1000 - Train Loss: 0.0158\n",
    "📘 Epoch 184/1000 - Train Loss: 0.0158\n",
    "📘 Epoch 185/1000 - Train Loss: 0.0163\n",
    "📘 Epoch 186/1000 - Train Loss: 0.0145\n",
    "📘 Epoch 187/1000 - Train Loss: 0.0160\n",
    "📘 Epoch 188/1000 - Train Loss: 0.0145\n",
    "📘 Epoch 189/1000 - Train Loss: 0.0149\n",
    "📘 Epoch 190/1000 - Train Loss: 0.0144\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch190.pt\n",
    "📘 Epoch 191/1000 - Train Loss: 0.0158\n",
    "📘 Epoch 192/1000 - Train Loss: 0.0151\n",
    "📘 Epoch 193/1000 - Train Loss: 0.0147\n",
    "📘 Epoch 194/1000 - Train Loss: 0.0142\n",
    "📘 Epoch 195/1000 - Train Loss: 0.0154\n",
    "📘 Epoch 196/1000 - Train Loss: 0.0146\n",
    "📘 Epoch 197/1000 - Train Loss: 0.0147\n",
    "📘 Epoch 198/1000 - Train Loss: 0.0143\n",
    "📘 Epoch 199/1000 - Train Loss: 0.0150\n",
    "📘 Epoch 200/1000 - Train Loss: 0.0149\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch200.pt\n",
    "📘 Epoch 201/1000 - Train Loss: 0.0134\n",
    "📘 Epoch 202/1000 - Train Loss: 0.0154\n",
    "📘 Epoch 203/1000 - Train Loss: 0.0137\n",
    "📘 Epoch 204/1000 - Train Loss: 0.0142\n",
    "📘 Epoch 205/1000 - Train Loss: 0.0142\n",
    "📘 Epoch 206/1000 - Train Loss: 0.0140\n",
    "📘 Epoch 207/1000 - Train Loss: 0.0142\n",
    "📘 Epoch 208/1000 - Train Loss: 0.0136\n",
    "📘 Epoch 209/1000 - Train Loss: 0.0145\n",
    "📘 Epoch 210/1000 - Train Loss: 0.0128\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch210.pt\n",
    "📘 Epoch 211/1000 - Train Loss: 0.0138\n",
    "📘 Epoch 212/1000 - Train Loss: 0.0138\n",
    "📘 Epoch 213/1000 - Train Loss: 0.0129\n",
    "📘 Epoch 214/1000 - Train Loss: 0.0141\n",
    "📘 Epoch 215/1000 - Train Loss: 0.0127\n",
    "📘 Epoch 216/1000 - Train Loss: 0.0136\n",
    "📘 Epoch 217/1000 - Train Loss: 0.0143\n",
    "📘 Epoch 218/1000 - Train Loss: 0.0127\n",
    "📘 Epoch 219/1000 - Train Loss: 0.0141\n",
    "📘 Epoch 220/1000 - Train Loss: 0.0149\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch220.pt\n",
    "📘 Epoch 221/1000 - Train Loss: 0.0127\n",
    "📘 Epoch 222/1000 - Train Loss: 0.0130\n",
    "📘 Epoch 223/1000 - Train Loss: 0.0122\n",
    "📘 Epoch 224/1000 - Train Loss: 0.0140\n",
    "📘 Epoch 225/1000 - Train Loss: 0.0117\n",
    "📘 Epoch 226/1000 - Train Loss: 0.0124\n",
    "📘 Epoch 227/1000 - Train Loss: 0.0139\n",
    "📘 Epoch 228/1000 - Train Loss: 0.0126\n",
    "📘 Epoch 229/1000 - Train Loss: 0.0134\n",
    "📘 Epoch 230/1000 - Train Loss: 0.0134\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch230.pt\n",
    "📘 Epoch 231/1000 - Train Loss: 0.0138\n",
    "📘 Epoch 232/1000 - Train Loss: 0.0117\n",
    "📘 Epoch 233/1000 - Train Loss: 0.0124\n",
    "📘 Epoch 234/1000 - Train Loss: 0.0126\n",
    "📘 Epoch 235/1000 - Train Loss: 0.0112\n",
    "📘 Epoch 236/1000 - Train Loss: 0.0125\n",
    "📘 Epoch 237/1000 - Train Loss: 0.0125\n",
    "📘 Epoch 238/1000 - Train Loss: 0.0129\n",
    "📘 Epoch 239/1000 - Train Loss: 0.0117\n",
    "📘 Epoch 240/1000 - Train Loss: 0.0130\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch240.pt\n",
    "📘 Epoch 241/1000 - Train Loss: 0.0122\n",
    "📘 Epoch 242/1000 - Train Loss: 0.0117\n",
    "📘 Epoch 243/1000 - Train Loss: 0.0118\n",
    "📘 Epoch 244/1000 - Train Loss: 0.0116\n",
    "📘 Epoch 245/1000 - Train Loss: 0.0131\n",
    "📘 Epoch 246/1000 - Train Loss: 0.0126\n",
    "📘 Epoch 247/1000 - Train Loss: 0.0114\n",
    "📘 Epoch 248/1000 - Train Loss: 0.0113\n",
    "📘 Epoch 249/1000 - Train Loss: 0.0113\n",
    "📘 Epoch 250/1000 - Train Loss: 0.0119\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch250.pt\n",
    "📘 Epoch 251/1000 - Train Loss: 0.0117\n",
    "📘 Epoch 252/1000 - Train Loss: 0.0114\n",
    "📘 Epoch 253/1000 - Train Loss: 0.0111\n",
    "📘 Epoch 254/1000 - Train Loss: 0.0111\n",
    "📘 Epoch 255/1000 - Train Loss: 0.0118\n",
    "📘 Epoch 256/1000 - Train Loss: 0.0119\n",
    "📘 Epoch 257/1000 - Train Loss: 0.0118\n",
    "📘 Epoch 258/1000 - Train Loss: 0.0106\n",
    "📘 Epoch 259/1000 - Train Loss: 0.0119\n",
    "📘 Epoch 260/1000 - Train Loss: 0.0110\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch260.pt\n",
    "📘 Epoch 261/1000 - Train Loss: 0.0111\n",
    "📘 Epoch 262/1000 - Train Loss: 0.0110\n",
    "📘 Epoch 263/1000 - Train Loss: 0.0113\n",
    "📘 Epoch 264/1000 - Train Loss: 0.0107\n",
    "📘 Epoch 265/1000 - Train Loss: 0.0104\n",
    "📘 Epoch 266/1000 - Train Loss: 0.0115\n",
    "📘 Epoch 267/1000 - Train Loss: 0.0114\n",
    "📘 Epoch 268/1000 - Train Loss: 0.0111\n",
    "📘 Epoch 269/1000 - Train Loss: 0.0113\n",
    "📘 Epoch 270/1000 - Train Loss: 0.0111\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch270.pt\n",
    "📘 Epoch 271/1000 - Train Loss: 0.0105\n",
    "📘 Epoch 272/1000 - Train Loss: 0.0101\n",
    "📘 Epoch 273/1000 - Train Loss: 0.0104\n",
    "📘 Epoch 274/1000 - Train Loss: 0.0111\n",
    "📘 Epoch 275/1000 - Train Loss: 0.0104\n",
    "📘 Epoch 276/1000 - Train Loss: 0.0099\n",
    "📘 Epoch 277/1000 - Train Loss: 0.0099\n",
    "📘 Epoch 278/1000 - Train Loss: 0.0106\n",
    "📘 Epoch 279/1000 - Train Loss: 0.0103\n",
    "📘 Epoch 280/1000 - Train Loss: 0.0110\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch280.pt\n",
    "📘 Epoch 281/1000 - Train Loss: 0.0113\n",
    "📘 Epoch 282/1000 - Train Loss: 0.0104\n",
    "📘 Epoch 283/1000 - Train Loss: 0.0107\n",
    "📘 Epoch 284/1000 - Train Loss: 0.0103\n",
    "📘 Epoch 285/1000 - Train Loss: 0.0102\n",
    "📘 Epoch 286/1000 - Train Loss: 0.0115\n",
    "📘 Epoch 287/1000 - Train Loss: 0.0104\n",
    "📘 Epoch 288/1000 - Train Loss: 0.0101\n",
    "📘 Epoch 289/1000 - Train Loss: 0.0098\n",
    "📘 Epoch 290/1000 - Train Loss: 0.0098\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch290.pt\n",
    "📘 Epoch 291/1000 - Train Loss: 0.0109\n",
    "📘 Epoch 292/1000 - Train Loss: 0.0096\n",
    "📘 Epoch 293/1000 - Train Loss: 0.0111\n",
    "📘 Epoch 294/1000 - Train Loss: 0.0100\n",
    "📘 Epoch 295/1000 - Train Loss: 0.0101\n",
    "📘 Epoch 296/1000 - Train Loss: 0.0105\n",
    "📘 Epoch 297/1000 - Train Loss: 0.0097\n",
    "📘 Epoch 298/1000 - Train Loss: 0.0106\n",
    "📘 Epoch 299/1000 - Train Loss: 0.0103\n",
    "📘 Epoch 300/1000 - Train Loss: 0.0095\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch300.pt\n",
    "📘 Epoch 301/1000 - Train Loss: 0.0092\n",
    "📘 Epoch 302/1000 - Train Loss: 0.0096\n",
    "📘 Epoch 303/1000 - Train Loss: 0.0107\n",
    "📘 Epoch 304/1000 - Train Loss: 0.0097\n",
    "📘 Epoch 305/1000 - Train Loss: 0.0096\n",
    "📘 Epoch 306/1000 - Train Loss: 0.0102\n",
    "📘 Epoch 307/1000 - Train Loss: 0.0101\n",
    "📘 Epoch 308/1000 - Train Loss: 0.0095\n",
    "📘 Epoch 309/1000 - Train Loss: 0.0106\n",
    "📘 Epoch 310/1000 - Train Loss: 0.0098\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch310.pt\n",
    "📘 Epoch 311/1000 - Train Loss: 0.0088\n",
    "📘 Epoch 312/1000 - Train Loss: 0.0098\n",
    "📘 Epoch 313/1000 - Train Loss: 0.0093\n",
    "📘 Epoch 314/1000 - Train Loss: 0.0101\n",
    "📘 Epoch 315/1000 - Train Loss: 0.0096\n",
    "📘 Epoch 316/1000 - Train Loss: 0.0087\n",
    "📘 Epoch 317/1000 - Train Loss: 0.0093\n",
    "📘 Epoch 318/1000 - Train Loss: 0.0098\n",
    "📘 Epoch 319/1000 - Train Loss: 0.0088\n",
    "📘 Epoch 320/1000 - Train Loss: 0.0095\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch320.pt\n",
    "📘 Epoch 321/1000 - Train Loss: 0.0090\n",
    "📘 Epoch 322/1000 - Train Loss: 0.0092\n",
    "📘 Epoch 323/1000 - Train Loss: 0.0096\n",
    "📘 Epoch 324/1000 - Train Loss: 0.0089\n",
    "📘 Epoch 325/1000 - Train Loss: 0.0093\n",
    "📘 Epoch 326/1000 - Train Loss: 0.0106\n",
    "📘 Epoch 327/1000 - Train Loss: 0.0091\n",
    "📘 Epoch 328/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 329/1000 - Train Loss: 0.0102\n",
    "📘 Epoch 330/1000 - Train Loss: 0.0089\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch330.pt\n",
    "📘 Epoch 331/1000 - Train Loss: 0.0093\n",
    "📘 Epoch 332/1000 - Train Loss: 0.0091\n",
    "📘 Epoch 333/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 334/1000 - Train Loss: 0.0087\n",
    "📘 Epoch 335/1000 - Train Loss: 0.0087\n",
    "📘 Epoch 336/1000 - Train Loss: 0.0091\n",
    "📘 Epoch 337/1000 - Train Loss: 0.0095\n",
    "📘 Epoch 338/1000 - Train Loss: 0.0095\n",
    "📘 Epoch 339/1000 - Train Loss: 0.0089\n",
    "📘 Epoch 340/1000 - Train Loss: 0.0091\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch340.pt\n",
    "📘 Epoch 341/1000 - Train Loss: 0.0085\n",
    "📘 Epoch 342/1000 - Train Loss: 0.0089\n",
    "📘 Epoch 343/1000 - Train Loss: 0.0093\n",
    "📘 Epoch 344/1000 - Train Loss: 0.0083\n",
    "📘 Epoch 345/1000 - Train Loss: 0.0090\n",
    "📘 Epoch 346/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 347/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 348/1000 - Train Loss: 0.0091\n",
    "📘 Epoch 349/1000 - Train Loss: 0.0089\n",
    "📘 Epoch 350/1000 - Train Loss: 0.0090\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch350.pt\n",
    "📘 Epoch 351/1000 - Train Loss: 0.0088\n",
    "📘 Epoch 352/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 353/1000 - Train Loss: 0.0082\n",
    "📘 Epoch 354/1000 - Train Loss: 0.0098\n",
    "📘 Epoch 355/1000 - Train Loss: 0.0082\n",
    "📘 Epoch 356/1000 - Train Loss: 0.0094\n",
    "📘 Epoch 357/1000 - Train Loss: 0.0085\n",
    "📘 Epoch 358/1000 - Train Loss: 0.0088\n",
    "📘 Epoch 359/1000 - Train Loss: 0.0085\n",
    "📘 Epoch 360/1000 - Train Loss: 0.0080\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch360.pt\n",
    "📘 Epoch 361/1000 - Train Loss: 0.0097\n",
    "📘 Epoch 362/1000 - Train Loss: 0.0082\n",
    "📘 Epoch 363/1000 - Train Loss: 0.0084\n",
    "📘 Epoch 364/1000 - Train Loss: 0.0091\n",
    "📘 Epoch 365/1000 - Train Loss: 0.0082\n",
    "📘 Epoch 366/1000 - Train Loss: 0.0088\n",
    "📘 Epoch 367/1000 - Train Loss: 0.0082\n",
    "📘 Epoch 368/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 369/1000 - Train Loss: 0.0084\n",
    "📘 Epoch 370/1000 - Train Loss: 0.0089\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch370.pt\n",
    "📘 Epoch 371/1000 - Train Loss: 0.0080\n",
    "📘 Epoch 372/1000 - Train Loss: 0.0091\n",
    "📘 Epoch 373/1000 - Train Loss: 0.0088\n",
    "📘 Epoch 374/1000 - Train Loss: 0.0084\n",
    "📘 Epoch 375/1000 - Train Loss: 0.0079\n",
    "📘 Epoch 376/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 377/1000 - Train Loss: 0.0076\n",
    "📘 Epoch 378/1000 - Train Loss: 0.0080\n",
    "📘 Epoch 379/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 380/1000 - Train Loss: 0.0074\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch380.pt\n",
    "📘 Epoch 381/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 382/1000 - Train Loss: 0.0086\n",
    "📘 Epoch 383/1000 - Train Loss: 0.0083\n",
    "📘 Epoch 384/1000 - Train Loss: 0.0079\n",
    "📘 Epoch 385/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 386/1000 - Train Loss: 0.0080\n",
    "📘 Epoch 387/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 388/1000 - Train Loss: 0.0076\n",
    "📘 Epoch 389/1000 - Train Loss: 0.0081\n",
    "📘 Epoch 390/1000 - Train Loss: 0.0084\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch390.pt\n",
    "📘 Epoch 391/1000 - Train Loss: 0.0081\n",
    "📘 Epoch 392/1000 - Train Loss: 0.0085\n",
    "📘 Epoch 393/1000 - Train Loss: 0.0079\n",
    "📘 Epoch 394/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 395/1000 - Train Loss: 0.0074\n",
    "📘 Epoch 396/1000 - Train Loss: 0.0079\n",
    "📘 Epoch 397/1000 - Train Loss: 0.0074\n",
    "📘 Epoch 398/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 399/1000 - Train Loss: 0.0071\n",
    "📘 Epoch 400/1000 - Train Loss: 0.0074\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch400.pt\n",
    "📘 Epoch 401/1000 - Train Loss: 0.0073\n",
    "📘 Epoch 402/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 403/1000 - Train Loss: 0.0064\n",
    "📘 Epoch 404/1000 - Train Loss: 0.0070\n",
    "📘 Epoch 405/1000 - Train Loss: 0.0081\n",
    "📘 Epoch 406/1000 - Train Loss: 0.0078\n",
    "📘 Epoch 407/1000 - Train Loss: 0.0077\n",
    "📘 Epoch 408/1000 - Train Loss: 0.0075\n",
    "📘 Epoch 409/1000 - Train Loss: 0.0074\n",
    "📘 Epoch 410/1000 - Train Loss: 0.0071\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch410.pt\n",
    "📘 Epoch 411/1000 - Train Loss: 0.0071\n",
    "📘 Epoch 412/1000 - Train Loss: 0.0073\n",
    "📘 Epoch 413/1000 - Train Loss: 0.0079\n",
    "📘 Epoch 414/1000 - Train Loss: 0.0074\n",
    "📘 Epoch 415/1000 - Train Loss: 0.0063\n",
    "📘 Epoch 416/1000 - Train Loss: 0.0080\n",
    "📘 Epoch 417/1000 - Train Loss: 0.0066\n",
    "📘 Epoch 418/1000 - Train Loss: 0.0072\n",
    "📘 Epoch 419/1000 - Train Loss: 0.0069\n",
    "📘 Epoch 420/1000 - Train Loss: 0.0072\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch420.pt\n",
    "📘 Epoch 421/1000 - Train Loss: 0.0072\n",
    "📘 Epoch 422/1000 - Train Loss: 0.0069\n",
    "📘 Epoch 423/1000 - Train Loss: 0.0069\n",
    "📘 Epoch 424/1000 - Train Loss: 0.0067\n",
    "📘 Epoch 425/1000 - Train Loss: 0.0068\n",
    "📘 Epoch 426/1000 - Train Loss: 0.0069\n",
    "📘 Epoch 427/1000 - Train Loss: 0.0068\n",
    "📘 Epoch 428/1000 - Train Loss: 0.0067\n",
    "📘 Epoch 429/1000 - Train Loss: 0.0071\n",
    "📘 Epoch 430/1000 - Train Loss: 0.0068\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch430.pt\n",
    "📘 Epoch 431/1000 - Train Loss: 0.0066\n",
    "📘 Epoch 432/1000 - Train Loss: 0.0069\n",
    "📘 Epoch 433/1000 - Train Loss: 0.0064\n",
    "📘 Epoch 434/1000 - Train Loss: 0.0065\n",
    "📘 Epoch 435/1000 - Train Loss: 0.0067\n",
    "📘 Epoch 436/1000 - Train Loss: 0.0067\n",
    "📘 Epoch 437/1000 - Train Loss: 0.0064\n",
    "📘 Epoch 438/1000 - Train Loss: 0.0070\n",
    "📘 Epoch 439/1000 - Train Loss: 0.0063\n",
    "📘 Epoch 440/1000 - Train Loss: 0.0056\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch440.pt\n",
    "📘 Epoch 441/1000 - Train Loss: 0.0063\n",
    "📘 Epoch 442/1000 - Train Loss: 0.0071\n",
    "📘 Epoch 443/1000 - Train Loss: 0.0062\n",
    "📘 Epoch 444/1000 - Train Loss: 0.0061\n",
    "📘 Epoch 445/1000 - Train Loss: 0.0070\n",
    "📘 Epoch 446/1000 - Train Loss: 0.0064\n",
    "📘 Epoch 447/1000 - Train Loss: 0.0062\n",
    "📘 Epoch 448/1000 - Train Loss: 0.0066\n",
    "📘 Epoch 449/1000 - Train Loss: 0.0060\n",
    "📘 Epoch 450/1000 - Train Loss: 0.0067\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch450.pt\n",
    "📘 Epoch 451/1000 - Train Loss: 0.0063\n",
    "📘 Epoch 452/1000 - Train Loss: 0.0062\n",
    "📘 Epoch 453/1000 - Train Loss: 0.0067\n",
    "📘 Epoch 454/1000 - Train Loss: 0.0062\n",
    "📘 Epoch 455/1000 - Train Loss: 0.0059\n",
    "📘 Epoch 456/1000 - Train Loss: 0.0069\n",
    "📘 Epoch 457/1000 - Train Loss: 0.0068\n",
    "📘 Epoch 458/1000 - Train Loss: 0.0059\n",
    "📘 Epoch 459/1000 - Train Loss: 0.0059\n",
    "📘 Epoch 460/1000 - Train Loss: 0.0062\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch460.pt\n",
    "📘 Epoch 461/1000 - Train Loss: 0.0062\n",
    "📘 Epoch 462/1000 - Train Loss: 0.0060\n",
    "📘 Epoch 463/1000 - Train Loss: 0.0063\n",
    "📘 Epoch 464/1000 - Train Loss: 0.0065\n",
    "📘 Epoch 465/1000 - Train Loss: 0.0057\n",
    "📘 Epoch 466/1000 - Train Loss: 0.0060\n",
    "📘 Epoch 467/1000 - Train Loss: 0.0061\n",
    "📘 Epoch 468/1000 - Train Loss: 0.0061\n",
    "📘 Epoch 469/1000 - Train Loss: 0.0060\n",
    "📘 Epoch 470/1000 - Train Loss: 0.0057\n",
    "✅ Saved checkpoint: checkpoints_baseline/char_transformer_epoch470.pt\n",
    "📘 Epoch 471/1000 - Train Loss: 0.0061\n",
    "📘 Epoch 472/1000 - Train Loss: 0.0063\n",
    "📘 Epoch 473/1000 - Train Loss: 0.0052\n",
    "📘 Epoch 474/1000 - Train Loss: 0.0062\n",
    "📘 Epoch 475/1000 - Train Loss: 0.0063"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3340b2c",
   "metadata": {},
   "source": [
    "## Test set prediction\n",
    "\n",
    "1. encode_text() and decode_text() are the same functions you used for your baseline dataset.\n",
    "2. SOS_IDX and EOS_IDX should be your special token indices (start/end).\n",
    "3. This uses greedy decoding only. No beam search or sampling needed.\n",
    "4. You can now submit predictions_normal.csv for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87cf1b",
   "metadata": {},
   "source": [
    "Load Model and Define Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33545510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Enjoy your day having extreme fun!\n",
      "Prediction: !nuf emertxe gnivah yad ruoy yojn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Force CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load checkpoint on CPU\n",
    "checkpoint_path = \"checkpoints_baseline/char_transformer_epoch500.pt\"\n",
    "baseline_model.load_state_dict(torch.load(checkpoint_path, map_location=device)[\"model_state\"])\n",
    "baseline_model.to(device)\n",
    "baseline_model.eval()\n",
    "\n",
    "# Vocabulary\n",
    "vocab = {c:i+3 for i,c in enumerate([chr(i) for i in range(32,127)])}\n",
    "inv_vocab = {i:c for c,i in vocab.items()}\n",
    "PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2\n",
    "\n",
    "def encode_text(text):\n",
    "    return [SOS_IDX] + [vocab[c] for c in text] + [EOS_IDX]\n",
    "\n",
    "def decode_text(ids):\n",
    "    return \"\".join([inv_vocab[i] for i in ids if i > 2])\n",
    "\n",
    "# Autoregressive prediction\n",
    "def generate_single_char_model(text, model, max_len=128):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor([encode_text(text)], dtype=torch.long, device=device)\n",
    "        output_ids = [SOS_IDX]\n",
    "\n",
    "        for t in range(max_len):\n",
    "            tgt_ids = torch.tensor([output_ids], dtype=torch.long, device=device)\n",
    "            logits = model(input_ids, tgt_ids)\n",
    "            next_id = logits[0, -1].argmax().item()\n",
    "            output_ids.append(next_id)\n",
    "            if next_id == EOS_IDX:\n",
    "                break\n",
    "\n",
    "        return decode_text(output_ids[1:])\n",
    "\n",
    "# Example\n",
    "sample_text = \"Enjoy your day having extreme fun!\"\n",
    "prediction = generate_single_char_model(sample_text, baseline_model)\n",
    "print(\"Input: \", sample_text)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93602b",
   "metadata": {},
   "source": [
    "Inference Testing (Single, Interactive Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using MPS for inference\n",
      "✅ Model loaded and set to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# --- 1. Setup ---\n",
    "\n",
    "# Define constants to match the training environment\n",
    "PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2\n",
    "VOCAB_SIZE = 95  # FIX: Hardcode the vocab size from the trained model\n",
    "MAX_LEN = 128    # Define a max generation length\n",
    "\n",
    "# --- Vocabulary and Helper Functions ---\n",
    "# Re-create the exact vocabulary used during training\n",
    "chars = [chr(i) for i in range(32, 127)]\n",
    "_vocab = {c: i + 3 for i, c in enumerate(chars)}\n",
    "INV_VOCAB = {i: c for c, i in _vocab.items()}\n",
    "\n",
    "def encode_text(text, add_special=True):\n",
    "    # FIX: Use the full version of the function that accepts 'add_special'\n",
    "    ids = [_vocab.get(ch, -1) for ch in text if ch in _vocab]\n",
    "    if add_special:\n",
    "        ids = [SOS_IDX] + ids + [EOS_IDX]\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "def decode_ids(ids):\n",
    "    \"\"\"Decodes a list of token IDs back to a string.\"\"\"\n",
    "    return \"\".join([INV_VOCAB.get(i, '') for i in ids if i not in {PAD_IDX, SOS_IDX, EOS_IDX}])\n",
    "\n",
    "# --- Device and Model Loading ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using MPS for inference\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ MPS not available, using CPU for inference\")\n",
    "\n",
    "# Instantiate your model architecture with the CORRECT vocab_size\n",
    "baseline_model = CharTransformer(vocab_size=VOCAB_SIZE, d_model=64, nhead=4, num_layers=2).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "checkpoint_path = \"checkpoints_baseline/char_transformer_epoch500.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "baseline_model.load_state_dict(checkpoint[\"model_state\"])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "baseline_model.eval()\n",
    "print(\"✅ Model loaded and set to evaluation mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Generating predictions on the test set...\n",
      "✅ Predictions generated. Here are the first 10 examples:\n",
      "                                                                                                             input                                                                                                     ground_truth                                                                                                             prediction\n",
      "0                                                        intimidated campaigns emerging marines spin bel cleansing                                                        gnisnaelc leb nips seniram gnigreme sngiapmac detadimitni      gnisnaelc leb nips seniram gnigreme sngiapmac detadimitni snaelc leb nips seniram gnignigreme sngiapmac detimitni\n",
      "1                                                                          salary lebanese wifi fury fab sta polly                                                                          yllop ats baf yruf ifiw esenabel yralas                   yllop ats baf yruf ifiw esenabel yralaso oodao ood llop ats baf yruf ififiw esenabel yralasoo ood oo\n",
      "2                                                               financing ahmed sexual cinematic puff malibu peach                                                               hcaep ubilam ffup citamenic lauxes demha gnicnanif              hcaep ubilam ffup citamenic lauxes demha gnicnanif oc caep ubilam ffupup citamenic lauxes demha gnicnanif\n",
      "3  n00 nickel disparity funded tutorials constrained bk 8 cellar wen advocacy surpass digitally discredit earliest  tseilrae tidercsid yllatigid ssaprus ycacovda new rallec 8 kb deniartsnoc slairotut dednuf ytirapsid lekcin 00n  tseilrae tidercsid yllatigid ssaprus ycacovda new rallec 8 kb deniartsnoc slairotut dednuf ytirapsid lekcin 00nlec 8 \n",
      "4                                          unveiled alliance cleric skinned illness permission destroyed stationed                                          denoitats deyortsed noissimrep ssenlli denniks cirelc ecnailla delievnu     denoitats deyortsed noissimrep ssenlli denniks cirelc ecnailla delievnuort noississimrep ssenlli denniks cirelc ec\n",
      "5                                                         input openings thinks sierra stimulate sheikh habit dull                                                         llud tibah hkiehs etalumits arreis skniht sgninepo tupni       llud tibah hkiehs etalumits arreis skniht sgninepo tupni lud tibah hkiehs etalumits arreis skniht sgninepo tupni\n",
      "6                                                       reforms lamps from hockey evening clones beyonce artillery                                                       yrellitra ecnoyeb senolc gnineve yekcoh morf spmal smrofer      yrellitra ecnoyeb senolc gnineve yekcoh morf spmal smroferrlitra ecnoyeb senolc gninineve yekcoh morf spmal smrof\n",
      "7                             ra hungary flush plush sorts spouse bananas defender protests lesser alexandra canal                             lanac ardnaxela ressel stsetorp rednefed sananab esuops stros hsulp hsulf yragnuh ar  lanac ardnaxela ressel stsetorp rednefed sananab esuops stros hsulp hsulf yragnuh artsetorp rednefed sananab esuops s\n",
      "8                                                                           worcester visitation rotary constantly                                                                           yltnatsnoc yrator noitatisiv retsecrow                     yltnatsnoc yrator noitatisiv retsecrowo ood oo aodoltnatsnoc yrator noitatatisiv retsecrowoo oo oo\n",
      "9                      neck m1 prescribe demands ev commanders s00 compensation inventions amc ranged faster nobel                      lebon retsaf degnar cma snoitnevni noitasnepmoc 00s srednammoc ve sdnamed ebircserp 1m kcen  lebon retsaf degnar cma snoitnevni noitasnepmoc 00s srednammoc ve sdnamed ebircserp 1m kcen onoitasnepmoc 000s sredna\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Test Set Prediction ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_on_test_set(model, data_loader, device):\n",
    "    \"\"\"Generates predictions for an entire test set and returns a DataFrame.\"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    # FIX: Make the loop more robust by iterating over 'batch'\n",
    "    for batch in data_loader:\n",
    "        src_padded = batch[0].to(device)\n",
    "        tgt_padded = batch[2] # For ground truth comparison\n",
    "\n",
    "        tgt_inp = torch.full((src_padded.size(0), 1), SOS_IDX, dtype=torch.long, device=device)\n",
    "\n",
    "        for _ in range(MAX_LEN):\n",
    "            logits = model(src_padded, tgt_inp)\n",
    "            next_token = logits[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "            tgt_inp = torch.cat([tgt_inp, next_token], dim=1)\n",
    "            if (tgt_inp == EOS_IDX).any(dim=1).all():\n",
    "                break\n",
    "\n",
    "        source_texts = [decode_ids(s.tolist()) for s in src_padded]\n",
    "        target_texts = [decode_ids(t.tolist()) for t in tgt_padded]\n",
    "        predicted_texts = [decode_ids(p.tolist()) for p in tgt_inp]\n",
    "        \n",
    "        for i in range(len(source_texts)):\n",
    "            results.append({\n",
    "                \"input\": source_texts[i],\n",
    "                \"ground_truth\": target_texts[i],\n",
    "                \"prediction\": predicted_texts[i]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n🔍 Generating predictions on the test set...\")\n",
    "predictions_df = predict_on_test_set(baseline_model, test_loader, device)\n",
    "print(\"✅ Predictions generated. Here are the first 10 examples:\")\n",
    "print(predictions_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Running interactive inference tests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input:      'hello world'\n",
      "Prediction: 'dlrow olleh'\n",
      "\n",
      "Input:      'PyTorch is great for building transformers.'\n",
      "Prediction: '.sremrofsnart gnidliub rof taerg si hcroyy'\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Inference Testing ---\n",
    "\n",
    "def generate_prediction(input_text, model, device):\n",
    "    \"\"\"Generates a prediction for a single input string.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # This function now works because encode_text is defined correctly above\n",
    "        src_tensor = encode_text(input_text, add_special=True).unsqueeze(0).to(device)\n",
    "        output_ids = [SOS_IDX]\n",
    "\n",
    "        for _ in range(MAX_LEN):\n",
    "            tgt_tensor = torch.tensor(output_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            logits = model(src_tensor, tgt_tensor)\n",
    "            next_id = logits[0, -1].argmax().item()\n",
    "            output_ids.append(next_id)\n",
    "            if next_id == EOS_IDX:\n",
    "                break\n",
    "        \n",
    "        return decode_ids(output_ids)\n",
    "\n",
    "print(\"\\n🤖 Running interactive inference tests...\")\n",
    "\n",
    "sample1 = \"hello world\"\n",
    "pred1 = generate_prediction(sample1, baseline_model, device)\n",
    "print(f\"\\nInput:      '{sample1}'\")\n",
    "print(f\"Prediction: '{pred1}'\")\n",
    "\n",
    "sample2 = \"PyTorch is great for building transformers.\"\n",
    "pred2 = generate_prediction(sample2, baseline_model, device)\n",
    "print(f\"\\nInput:      '{sample2}'\")\n",
    "print(f\"Prediction: '{pred2}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3b2b1",
   "metadata": {},
   "source": [
    "## Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using mps for inference\n",
      "✅ Model loaded successfully.\n",
      "\n",
      "Reading data from ./../data/test.csv...\n",
      "Generating predictions for each row...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "➡️ Processing rows:   0%|          | 0/2000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "➡️ Processing rows: 100%|██████████| 2000/2000 [15:35<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 Success! Predictions saved to: ./predictions/test_predictions.csv\n",
      "\n",
      "Here's a preview of the final data:\n",
      "                                                                                                             input                                                                                                           target                                                                                                      predictions\n",
      "0                                                        intimidated campaigns emerging marines spin bel cleansing                                                        gnisnaelc leb nips seniram gnigreme sngiapmac detadimitni                                                        gnisnaelc leb nips seniram gnigreme sngiapmac detadimitni\n",
      "1                                                                          salary lebanese wifi fury fab sta polly                                                                          yllop ats baf yruf ifiw esenabel yralas                                                                          yllop ats baf yruf ifiw esenabel yralas\n",
      "2                                                               financing ahmed sexual cinematic puff malibu peach                                                               hcaep ubilam ffup citamenic lauxes demha gnicnanif                                                               hcaep ubilam ffup citamenic lauxes demha gnicnanif\n",
      "3  n00 nickel disparity funded tutorials constrained bk 8 cellar wen advocacy surpass digitally discredit earliest  tseilrae tidercsid yllatigid ssaprus ycacovda new rallec 8 kb deniartsnoc slairotut dednuf ytirapsid lekcin 00n  tseilrae tidercsid yllatigid ssaprus ycacovda new rallec 8 kb deniartsnoc slairotut dednuf ytirapsid lekcin 00n\n",
      "4                                          unveiled alliance cleric skinned illness permission destroyed stationed                                          denoitats deyortsed noissimrep ssenlli denniks cirelc ecnailla delievnu                                          denoitats deyortsed noissimrep ssenlli denniks cirelc ecnailla delievnu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- 1. Setup (Model, Constants, and Helpers) ---\n",
    "# Ensure this setup matches the environment you used for training and previous testing.\n",
    "\n",
    "# Define constants\n",
    "PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2\n",
    "VOCAB_SIZE = 95\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Vocabulary and Helper Functions\n",
    "chars = [chr(i) for i in range(32, 127)]\n",
    "_vocab = {c: i + 3 for i, c in enumerate(chars)}\n",
    "INV_VOCAB = {i: c for c, i in _vocab.items()}\n",
    "\n",
    "def encode_text(text, add_special=True):\n",
    "    ids = [_vocab.get(ch, -1) for ch in text if ch in _vocab]\n",
    "    if add_special:\n",
    "        ids = [SOS_IDX] + ids + [EOS_IDX]\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "def decode_ids(ids):\n",
    "    return \"\".join([INV_VOCAB.get(i, '') for i in ids if i not in {PAD_IDX, SOS_IDX, EOS_IDX}])\n",
    "\n",
    "# Device and Model Loading\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"✅ Using {device} for inference\")\n",
    "\n",
    "# Instantiate your model architecture\n",
    "# This needs the CharTransformer class definition from your original script\n",
    "baseline_model = CharTransformer(vocab_size=VOCAB_SIZE, d_model=64, nhead=4, num_layers=2).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "checkpoint_path = \"checkpoints_baseline/char_transformer_epoch500.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "baseline_model.load_state_dict(checkpoint[\"model_state\"])\n",
    "baseline_model.eval()\n",
    "print(\"✅ Model loaded successfully.\")\n",
    "\n",
    "\n",
    "# --- 2. Single Prediction Function ---\n",
    "\n",
    "def generate_prediction(input_text, model, device):\n",
    "    \"\"\"Generates a prediction for a single input string.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src_tensor = encode_text(input_text, add_special=True).unsqueeze(0).to(device)\n",
    "        output_ids = [SOS_IDX]\n",
    "\n",
    "        for _ in range(MAX_LEN):\n",
    "            tgt_tensor = torch.tensor(output_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            logits = model(src_tensor, tgt_tensor)\n",
    "            next_id = logits[0, -1].argmax().item()\n",
    "            output_ids.append(next_id)\n",
    "            if next_id == EOS_IDX:\n",
    "                break\n",
    "        \n",
    "        return decode_ids(output_ids)\n",
    "\n",
    "\n",
    "# --- 3. Main Script to Process CSV ---\n",
    "\n",
    "# Define file paths\n",
    "input_csv_path = \"./../data/test.csv\"\n",
    "output_dir = \"./predictions\"\n",
    "output_csv_path = os.path.join(output_dir, \"test_predictions.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the test data\n",
    "print(f\"\\nReading data from {input_csv_path}...\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "predictions_list = []\n",
    "\n",
    "print(\"Generating predictions for each row...\")\n",
    "# Use tqdm to create a progress bar\n",
    "for input_text in tqdm(df['input'], desc=\"➡️ Processing rows\"):\n",
    "    # Generate a prediction for the current input text\n",
    "    prediction = generate_prediction(input_text, baseline_model, device)\n",
    "    # Add the prediction to our list\n",
    "    predictions_list.append(prediction)\n",
    "\n",
    "# Add the list of predictions as a new column in the DataFrame\n",
    "df['predictions'] = predictions_list\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n🎉 Success! Predictions saved to: {output_csv_path}\")\n",
    "print(\"\\nHere's a preview of the final data:\")\n",
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c228213",
   "metadata": {},
   "source": [
    "# Evaluation & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18880acd",
   "metadata": {},
   "source": [
    "##  Metrics evaluation script for both BLT and baseline models\n",
    "\n",
    "1.\tToken-level accuracy\n",
    "2.\tAverage sequence length (input tokens vs predicted tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_predictions(pred_csv_path, original_csv_path):\n",
    "    # Load predictions\n",
    "    df_pred = pd.read_csv(pred_csv_path)\n",
    "    df_orig = pd.read_csv(original_csv_path)\n",
    "\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "    total_input_len = 0\n",
    "    total_output_len = 0\n",
    "\n",
    "    for idx in range(len(df_pred)):\n",
    "        pred = str(df_pred.loc[idx, \"prediction\"])\n",
    "        target = str(df_orig.loc[idx, \"target\"])\n",
    "        input_str = str(df_orig.loc[idx, \"input\"])\n",
    "\n",
    "        # Token-level comparison\n",
    "        min_len = min(len(pred), len(target))\n",
    "        correct_tokens += sum([pred[i] == target[i] for i in range(min_len)])\n",
    "        total_tokens += len(target)\n",
    "\n",
    "        # Sequence length stats\n",
    "        total_input_len += len(input_str)\n",
    "        total_output_len += len(pred)\n",
    "\n",
    "    token_accuracy = 100.0 * correct_tokens / total_tokens\n",
    "    avg_input_len = total_input_len / len(df_pred)\n",
    "    avg_output_len = total_output_len / len(df_pred)\n",
    "\n",
    "    print(f\"✅ Evaluation for {pred_csv_path}\")\n",
    "    print(f\"Token-level Accuracy: {token_accuracy:.2f}%\")\n",
    "    print(f\"Average input length: {avg_input_len:.2f} chars\")\n",
    "    print(f\"Average predicted length: {avg_output_len:.2f} chars\")\n",
    "    print(\"-\" * 50)\n",
    "    return token_accuracy, avg_input_len, avg_output_len\n",
    "\n",
    "\n",
    "# --- Evaluate BLT predictions ---\n",
    "blt_acc, blt_in_len, blt_out_len = evaluate_predictions(\n",
    "    \"./prediction/blt_predictions.csv\", \"./../data/test.csv\"\n",
    ")\n",
    "\n",
    "# --- Evaluate Baseline predictions ---\n",
    "baseline_acc, base_in_len, base_out_len = evaluate_predictions(\n",
    "    \"./prediction/predictions_baseline.csv\", \"./../data/test.csv\"\n",
    ")\n",
    "\n",
    "# --- Comparison Summary ---\n",
    "print(\"📊 Comparison Summary:\")\n",
    "print(f\"BLT      | Acc: {blt_acc:.2f}%, Avg Input: {blt_in_len:.2f}, Avg Pred: {blt_out_len:.2f}\")\n",
    "print(f\"Baseline | Acc: {baseline_acc:.2f}%, Avg Input: {base_in_len:.2f}, Avg Pred: {base_out_len:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c6da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
